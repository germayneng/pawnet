{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 02-Exploration and extension to pytorch lightning \n\nGoal of this notebook is to just explore the dataset, set up some basic utilities ","metadata":{}},{"cell_type":"code","source":"%%bash\npip install attrdict\npip install timm\npip install pytorch-lightning==1.4.0","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:30:35.824818Z","iopub.execute_input":"2021-11-23T12:30:35.825263Z","iopub.status.idle":"2021-11-23T12:31:00.130328Z","shell.execute_reply.started":"2021-11-23T12:30:35.825167Z","shell.execute_reply":"2021-11-23T12:31:00.129432Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nimport matplotlib.pyplot as plt\nimport os\nimport tqdm\n\nimport seaborn as sns\nfrom torchvision.io import read_image\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\nfrom attrdict import AttrDict\nimport torch\nimport yaml\nfrom sklearn.model_selection import StratifiedKFold\nimport copy\nimport pickle\n# from tqdm import tqdm_notebook\n\n# additional lightning \n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-11-23T13:19:38.752945Z","iopub.execute_input":"2021-11-23T13:19:38.753547Z","iopub.status.idle":"2021-11-23T13:19:38.761420Z","shell.execute_reply.started":"2021-11-23T13:19:38.753507Z","shell.execute_reply":"2021-11-23T13:19:38.760694Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# check the package version to get reproducible env \n# source: https://www.kaggle.com/rtatman/get-the-versions-of-imported-packages\n\n\"\"\"\nTo be used for kaggle notebook\n\"\"\"\n\nimport pkg_resources\nimport types\ndef get_imports():\n    for name, val in globals().items():\n        if isinstance(val, types.ModuleType):\n            # Split ensures you get root package, \n            # not just imported function\n            name = val.__name__.split(\".\")[0]\n\n        elif isinstance(val, type):\n            name = val.__module__.split(\".\")[0]\n\n        # Some packages are weird and have different\n        # imported names vs. system names\n        if name == \"PIL\":\n            name = \"Pillow\"\n        elif name == \"sklearn\":\n            name = \"scikit-learn\"\n\n        yield name\nimports = list(set(get_imports()))\n\nrequirements = []\nfor m in pkg_resources.working_set:\n    if m.project_name in imports and m.project_name!=\"pip\":\n        requirements.append((m.project_name, m.version))\n\nfor r in requirements:\n    print(\"{}=={}\".format(*r))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:31:24.742544Z","iopub.execute_input":"2021-11-23T12:31:24.742822Z","iopub.status.idle":"2021-11-23T12:31:24.756107Z","shell.execute_reply.started":"2021-11-23T12:31:24.742792Z","shell.execute_reply":"2021-11-23T12:31:24.755357Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n\n\n\"\"\"\nTo add to utility.py\n\"\"\"\n\ndef seed_everything(seed=1234):\n    \"\"\"\n    Utility function to seed everything\n    source: https://www.kaggle.com/bminixhofer/deterministic-neural-networks-using-pytorch\n    \"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n    \n\ndef read_yaml(filename):\n    \"\"\"\n    Read yaml configuation and returns the dict\n\n    Parameters\n    ----------\n    filename: string\n        Path including yaml file name\n    \"\"\"\n\n    with open(filename) as f:\n        config = yaml.safe_load(f)\n\n    return config\n\n\n    \n# configs\n\n# config is different in kaggle\n\n\nclass BaseConfigLoader:\n    \n    def __init__(self,config_path):\n        self.config = read_yaml(config_path)\n            \n    def load_config(self):\n        return AttrDict(self.config)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:31:30.354989Z","iopub.execute_input":"2021-11-23T12:31:30.355770Z","iopub.status.idle":"2021-11-23T12:31:30.363134Z","shell.execute_reply.started":"2021-11-23T12:31:30.355730Z","shell.execute_reply":"2021-11-23T12:31:30.362342Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# load config\n# this object manages all the configurations\n\nbase_config_manager = BaseConfigLoader(\"../input/config/config.yaml\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T14:08:58.513210Z","iopub.execute_input":"2021-11-23T14:08:58.513502Z","iopub.status.idle":"2021-11-23T14:08:58.525955Z","shell.execute_reply.started":"2021-11-23T14:08:58.513465Z","shell.execute_reply":"2021-11-23T14:08:58.525110Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data\n\nWe will load the data by creating torch datasets as well as dataloader","metadata":{}},{"cell_type":"code","source":"# this is specific to kaggle\n# if running in GCS, replace with our GCP bucket \n# get cache location of the dataset \n# GCS_DS_PATH = KaggleDatasets().get_gcs_path()\nfile_path = base_config_manager.load_config().filepath.kaggle #\"/kaggle/input/petfinder-pawpularity-score/\"\n\n\ntrain_df = pd.read_csv(os.path.join(file_path,\"train.csv\"))\ntest_df = pd.read_csv(os.path.join(file_path,\"test.csv\"))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:32:53.852690Z","iopub.execute_input":"2021-11-23T12:32:53.853381Z","iopub.status.idle":"2021-11-23T12:32:53.894856Z","shell.execute_reply.started":"2021-11-23T12:32:53.853343Z","shell.execute_reply":"2021-11-23T12:32:53.894121Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:33:01.073298Z","iopub.execute_input":"2021-11-23T12:33:01.074171Z","iopub.status.idle":"2021-11-23T12:33:01.102798Z","shell.execute_reply.started":"2021-11-23T12:33:01.074122Z","shell.execute_reply":"2021-11-23T12:33:01.101990Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:33:01.701053Z","iopub.execute_input":"2021-11-23T12:33:01.701587Z","iopub.status.idle":"2021-11-23T12:33:01.713942Z","shell.execute_reply.started":"2021-11-23T12:33:01.701550Z","shell.execute_reply":"2021-11-23T12:33:01.712974Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class pawnetDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Dataset\n    Based on template https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n    \"\"\"\n    def __init__(self,annotation_df, img_dir,transform=None,target_transform=None,test=False,custom_len=None):\n        self.annotation_df = annotation_df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n        self.test=test # if dataset contains labels\n        self.custom_len=custom_len # if we want to define our own epoch\n        \n        \n    def __len__(self):\n        \"\"\"Define 1 epoch\"\"\"\n        if self.custom_len is None:\n            return len(self.annotation_df)\n        else:\n            return self.custom_len\n    \n    def __getitem__(self,idx):\n        \"\"\"called batch num of times\"\"\"\n        img_path = os.path.join(self.img_dir, self.annotation_df.iloc[idx, 0]) # ID is column index 0\n        image = read_image(img_path+\".jpg\")\n        if self.test:\n            label = 0\n        else:\n            label = self.annotation_df.iloc[idx, 13] # Pawpularity is column index 13\n            \n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:33:07.803272Z","iopub.execute_input":"2021-11-23T12:33:07.803811Z","iopub.status.idle":"2021-11-23T12:33:07.813181Z","shell.execute_reply.started":"2021-11-23T12:33:07.803776Z","shell.execute_reply":"2021-11-23T12:33:07.812005Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Train basic models ","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom timm import create_model\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:33:31.017404Z","iopub.execute_input":"2021-11-23T12:33:31.017964Z","iopub.status.idle":"2021-11-23T12:33:31.168100Z","shell.execute_reply.started":"2021-11-23T12:33:31.017925Z","shell.execute_reply":"2021-11-23T12:33:31.167284Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\n\nclass pawNetBasic(pl.LightningModule):\n    \"\"\"\n    First cut basic pawNet model\n    we will improve on this - this serves as skeleton code\n    for other models\n    \n    timm contains collection of several pretrained models\n    \n    This is a lightning variant *\n    \n    \n    lightning model requires the following methods:\n    1. forward \n    2. training_step (logic inside the iteration loop) , validation_step, test_step (not stable on tpu)\n    3. training_epoch_end, validation_epoch_end\n    4. configure_optimizers \n    \n    other configurable list here https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html\n    \n    \"\"\"\n    \n    def __init__(self,criterion, dropout=0.2):\n        super().__init__()\n        self.dropout = 0.2\n        self._criterion = criterion\n        self.train_loss = []\n        self.train_rmse = []\n        self.valid_rmse = []\n        \n        # initialize layers\n        # https://fastai.github.io/timmdocs/tutorial_feature_extractor\n        # remove FCL by setting num_classes=0\n        self.pretrained = create_model(\n            base_config_manager.load_config().model.pretrained, \n            pretrained=True, \n            num_classes=0, \n            in_chans=3\n        )\n        self.global_avg_pooling = torch.nn.AdaptiveAvgPool2d(1)\n        self.linear_1 = torch.nn.Linear(in_features=512,out_features=500)\n        self.prelu = torch.nn.PReLU()\n        self.linear_2 = torch.nn.Linear(in_features=500,out_features=1)\n        self.batchnorm = nn.BatchNorm1d(500)\n        \n    def forward(self,x):\n        # TODO: add dropout\n        out = self.pretrained(x)\n        out = out.view(out.size(0), -1) # reshape for linear\n        out = self.linear_1(out)\n        out = self.prelu(out)\n        out = self.batchnorm(out)\n        out = self.linear_2(out)\n        \n        \n        \n        return out\n    \n    \n    def training_step(self, batch, batch_idx):\n        \"\"\"\n        logic instead batch loop\n        \"\"\"\n        loss, pred, labels = self.__share_step(batch, 'train')\n        \n        return {'loss': loss, 'pred': pred, 'labels': labels}\n        \n    def validation_step(self, batch, batch_idx):\n        \"\"\"\n        logic instead batch loop for validation\n        \"\"\"\n        \n        loss, pred, labels = self.__share_step(batch, 'val')\n        return {'loss': loss, 'pred': pred, 'labels': labels}\n    \n    def __share_step(self, batch, mode):\n        images, labels = batch\n        labels = labels.float() / 100.0\n        \n        logits = self.forward(images).squeeze(1)\n        loss = self._criterion(logits, labels)\n        \n        # return logloss for training mode, scaled for others\n        pred = logits.sigmoid().detach().cpu() * 100.\n        labels = labels.detach().cpu() * 100.\n        return loss, pred, labels\n        \n    def training_epoch_end(self, outputs):\n        \"\"\"\n        called every end of epoch, contains logic\n        at end of epoch\n        \"\"\"\n        self.__share_epoch_end(outputs, mode = 'train')\n\n    def validation_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, mode = 'val')    \n        \n    def __share_epoch_end(self, outputs, mode):\n        \"\"\"\n        output is a list of output defined in\n        `training_step` as well as `validation_step`.\n        Need to iterate through each iteration's output.\n        the output was a dict\n        \"\"\"\n        preds = []\n        labels = []\n        losses = []\n        for out in outputs:\n            pred, label, loss = out['pred'], out['labels'], out[\"loss\"]\n            preds.append(pred)\n            labels.append(label)\n            losses.append(loss.view(-1,1))\n        preds = torch.cat(preds)\n        labels = torch.cat(labels)\n        losses = torch.cat(losses)\n        if mode == \"train\":\n            loglogss_metrics = losses.mean() # average logloss across iterations\n            self.log(f'{mode}_logloss', loglogss_metrics, prog_bar=True)\n        else:\n            print(f\"{mode}: skip logging for logloss\")\n            \n        # RMSE\n        metrics = torch.sqrt(((labels - preds) ** 2).mean())\n        # https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html\n        # automatic accumulation at end of epoch for training, true always for test,validation loops\n        self.log(f'{mode}_RMSE_loss', metrics, prog_bar=True)\n        \n        \n    def configure_optimizers(self):\n        \"\"\"\n        https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.lightning.html#pytorch_lightning.core.lightning.LightningModule.configure_optimizers\n        \n        Any of these 6 options.\n\n        Single optimizer.\n\n        List or Tuple of optimizers.\n\n        Two lists - The first list has multiple optimizers, and the second has multiple LR schedulers (or multiple lr_scheduler_config).\n\n        Dictionary, with an \"optimizer\" key, and (optionally) a \"lr_scheduler\" key whose value is a single LR scheduler or lr_scheduler_config.\n\n        Tuple of dictionaries as described above, with an optional \"frequency\" key.\n\n        None - Fit will run without any optimizer.\n        \"\"\"\n        opt = torch.optim.Adam(self.parameters())\n  \n        return [opt]      ","metadata":{"execution":{"iopub.status.busy":"2021-11-23T14:17:11.636563Z","iopub.execute_input":"2021-11-23T14:17:11.636938Z","iopub.status.idle":"2021-11-23T14:17:11.658971Z","shell.execute_reply.started":"2021-11-23T14:17:11.636901Z","shell.execute_reply":"2021-11-23T14:17:11.657994Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":"# Preparing for training - lightning variant \n\n* create relevant transformations, validation splits\n* what this version differs is that we will be using the pytorch lightning framework - this allows easy TPU access for training \n\nlightning walkthrough: \nhttps://pytorch-lightning.readthedocs.io/en/latest/starter/introduction_guide.html\n<br>\nhttps://devblog.pytorchlightning.ai/train-anything-with-lightning-custom-loops-4be32314c961\n<br>\nhttps://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/loop_examples/mnist_lite.py\n<br>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nAll pre-trained models expect input images normalized in the same way, \ni.e. mini-batches of 3-channel RGB images of shape (3 x H x W), \nwhere H and W are expected to be at least 224. \nThe images have to be loaded in to a range of [0, 1] and then \nnormalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. \nYou can use the following transform to normalize:\n\nhttps://pytorch.org/vision/stable/models.html\n\n\"\"\"\ntrain_transformation = T.Compose(\n            [\n                T.Resize([224,224]),# imgnet needs at least 224\n                T.RandomHorizontalFlip(),\n                T.RandomVerticalFlip(),\n                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n            ]\n        )\n# train_data = pawnetDataset(annotation_df=train_df,img_dir = os.path.join(file_path,\"train\"),transform = train_transformation)\n# # batchsize should be parameter in config\n# train_loader = torch.utils.data.DataLoader(train_data,batch_size=64,num_workers =2, shuffle=True)\n\n\ntest_transformation = T.Compose([\n                T.Resize([224,224]),# imgnet needs at least 224\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n                ]\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:34:27.473132Z","iopub.execute_input":"2021-11-23T12:34:27.473692Z","iopub.status.idle":"2021-11-23T12:34:27.481946Z","shell.execute_reply.started":"2021-11-23T12:34:27.473654Z","shell.execute_reply":"2021-11-23T12:34:27.481287Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class PetfinderDataModule(LightningDataModule):\n    \"\"\"\n    Lightning datamodule to handle all loaders\n    \"\"\"\n    def __init__(\n        self,\n        img_dir, # os.path.join(file_path,\"train\")\n        train_df,\n        val_df,\n        train_transformation,\n        test_transformation,\n        batch_size = 64,\n        num_workers = 2\n    ):\n        super().__init__()\n        self.img_dir = img_dir\n        self._train_df = train_df\n        self._val_df = val_df\n        self.train_transformation = train_transformation\n        self.test_transformation = test_transformation\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n\n\n    def train_dataloader(self):\n        train_data = pawnetDataset(annotation_df=self._train_df,img_dir = self.img_dir ,transform = self.train_transformation) # can set custom len to let model exceed training size (since we are augmenting)\n        return torch.utils.data.DataLoader(train_data,batch_size=self.batch_size,num_workers =self.num_workers, shuffle=True)\n\n    def val_dataloader(self):\n        val_data = pawnetDataset(annotation_df=self._val_df,img_dir = self.img_dir, transform = self.test_transformation)\n        return torch.utils.data.DataLoader(val_data,batch_size=self.batch_size,num_workers =self.num_workers, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T14:11:13.365715Z","iopub.execute_input":"2021-11-23T14:11:13.366174Z","iopub.status.idle":"2021-11-23T14:11:13.384979Z","shell.execute_reply.started":"2021-11-23T14:11:13.366135Z","shell.execute_reply":"2021-11-23T14:11:13.384028Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:12:54.119896Z","iopub.execute_input":"2021-11-22T13:12:54.120832Z","iopub.status.idle":"2021-11-22T13:12:54.127352Z","shell.execute_reply.started":"2021-11-22T13:12:54.120797Z","shell.execute_reply":"2021-11-22T13:12:54.125898Z"}}},{"cell_type":"code","source":"seed_everything()\n\n\n# perfrom stratified sampling k fold model training\nskf = StratifiedKFold(n_splits = base_config_manager.load_config().model.n_splits, shuffle = True, random_state = 1)\nsplits = skf.split(train_df[\"Id\"],train_df[\"Pawpularity\"])\n\n\nskf_train_list = [] # to store across folds\nskf_valid_list = [] # to store across folds\n\nfor i, (train_index, test_index) in enumerate(splits):\n    print(\"\\n Starting: fold {}\".format(i+1))\n    \n    # initialize model \n    criterion = torch.nn.BCEWithLogitsLoss()\n\n    X_train, X_valid = train_df.iloc[train_index], train_df.iloc[test_index]\n    X_train.reset_index(inplace=True,drop=True)\n    X_valid.reset_index(inplace=True,drop=True)\n    \n    # build datamodule\n    datamodule = PetfinderDataModule(img_dir = os.path.join(file_path,\"train\"),\n                                     train_df=X_train,\n                                     val_df=X_valid,\n                                     train_transformation=train_transformation,\n                                     test_transformation=test_transformation,\n                                     batch_size=base_config_manager.load_config().model.batch_size,\n                                     num_workers=base_config_manager.load_config().model.num_workers)\n    \n    \n    \n    model = pawNetBasic(criterion=criterion)\n    model.summarize()\n    earystopping = EarlyStopping(monitor=\"val_RMSE_loss\")\n    lr_monitor = callbacks.LearningRateMonitor()\n    loss_checkpoint = callbacks.ModelCheckpoint(\n        filename=\"best_loss\",\n        monitor=\"val_RMSE_loss\",\n        save_top_k=1,\n        mode=\"min\",\n        save_last=True,\n    )\n    logger = TensorBoardLogger(\"pawnet_lightning_resnet\")\n    \n    trainer = pl.Trainer(\n        logger=logger, # tensorboard logger\n        max_epochs=base_config_manager.load_config().model.epoch,\n        callbacks=[lr_monitor, loss_checkpoint, earystopping],\n         gpus=1,progress_bar_refresh_rate=1,accumulate_grad_batches=1\n    )\n    trainer.fit(model, datamodule=datamodule)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T14:17:16.342743Z","iopub.execute_input":"2021-11-23T14:17:16.343182Z","iopub.status.idle":"2021-11-23T14:17:32.577440Z","shell.execute_reply.started":"2021-11-23T14:17:16.343146Z","shell.execute_reply":"2021-11-23T14:17:32.576003Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n\n# https://stackoverflow.com/questions/36700404/tensorflow-opening-log-data-written-by-summarywriter\n\npath = [x for x in os.listdir(\"./pawnet_lightning_resnet/default/version_0/\") if x.startswith(\"events\")][0]\nevent_acc = EventAccumulator(os.path.join(\"pawnet_lightning_resnet/default/version_0/\",path), size_guidance={'scalars': 0})\nevent_acc.Reload()\n\nscalars = {}\nfor tag in event_acc.Tags()['scalars']:\n    events = event_acc.Scalars(tag)\n    scalars[tag] = [event.value for event in events]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:36:30.759823Z","iopub.execute_input":"2021-11-23T13:36:30.760414Z","iopub.status.idle":"2021-11-23T13:36:30.767970Z","shell.execute_reply.started":"2021-11-23T13:36:30.760375Z","shell.execute_reply":"2021-11-23T13:36:30.766989Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"# this allow us to plot all metrics\nscalars","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:36:35.318158Z","iopub.execute_input":"2021-11-23T13:36:35.318699Z","iopub.status.idle":"2021-11-23T13:36:35.323586Z","shell.execute_reply.started":"2021-11-23T13:36:35.318662Z","shell.execute_reply":"2021-11-23T13:36:35.322876Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# save\nwith open(\"scalars.pkl\",\"wb\") as fout:\n    pickle.dump(scalars,fout)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:25:09.736513Z","iopub.execute_input":"2021-11-23T13:25:09.737112Z","iopub.status.idle":"2021-11-23T13:25:09.742135Z","shell.execute_reply.started":"2021-11-23T13:25:09.737070Z","shell.execute_reply":"2021-11-23T13:25:09.741375Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"# Load tensorboard (doesnt seem to work on kaggle) ","metadata":{}},{"cell_type":"code","source":"# %load_ext tensorboard\n\n# %tensorboard --logdir ./pawnet_lightning_resnet","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}