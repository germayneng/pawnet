{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if we can load trained weights - make modifications to the model class (to save intermediated feature maps) needed for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TLDR: yes it works !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# pip install attrdict\n",
    "# pip install timm\n",
    "# pip install pytorch-lightning==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from attrdict import AttrDict\n",
    "import torch\n",
    "import yaml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy\n",
    "import pickle\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# additional lightning \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from timm import create_model\n",
    "\n",
    "\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T10:11:34.385190Z",
     "iopub.status.busy": "2021-11-27T10:11:34.384290Z",
     "iopub.status.idle": "2021-11-27T10:11:34.389955Z",
     "shell.execute_reply": "2021-11-27T10:11:34.389022Z",
     "shell.execute_reply.started": "2021-11-27T10:11:34.385140Z"
    }
   },
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T10:33:30.908359Z",
     "iopub.status.busy": "2021-11-27T10:33:30.907875Z",
     "iopub.status.idle": "2021-11-27T10:33:31.072595Z",
     "shell.execute_reply": "2021-11-27T10:33:31.071415Z",
     "shell.execute_reply.started": "2021-11-27T10:33:30.908309Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/36700404/tensorflow-opening-log-data-written-by-summarywriter\n",
    "\n",
    "resnet_list = []\n",
    "for i in range(5):\n",
    "    print(f\"\\n Fold: {i}==================================================\")\n",
    "    path = [x for x in os.listdir(f\"../input/02-pytorch-lightning-variant/pawnet_lightning_resnet/default/version_{i}/\") if x.startswith(\"events\")][0]\n",
    "    event_acc = EventAccumulator(os.path.join(f\"../input/02-pytorch-lightning-variant/pawnet_lightning_resnet/default/version_{i}/\",path), size_guidance={'scalars': 0})\n",
    "    event_acc.Reload()\n",
    "\n",
    "    scalars = {}\n",
    "    for tag in event_acc.Tags()['scalars']:\n",
    "        events = event_acc.Scalars(tag)\n",
    "        scalars[tag] = [event.value for event in events]\n",
    "    resnet_list.append(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T10:33:31.946360Z",
     "iopub.status.busy": "2021-11-27T10:33:31.946068Z",
     "iopub.status.idle": "2021-11-27T10:33:31.954037Z",
     "shell.execute_reply": "2021-11-27T10:33:31.953187Z",
     "shell.execute_reply.started": "2021-11-27T10:33:31.946330Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet_val = 0\n",
    "resnet_training_curve = []\n",
    "resnet_validation_curve = []\n",
    "for f in resnet_list:\n",
    "    print(f[\"val_RMSE_loss\"][-1])\n",
    "    resnet_val +=f[\"val_RMSE_loss\"][-1] / 5\n",
    "print(f\"AVG: {resnet_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T10:33:33.085086Z",
     "iopub.status.busy": "2021-11-27T10:33:33.084466Z",
     "iopub.status.idle": "2021-11-27T10:33:33.148964Z",
     "shell.execute_reply": "2021-11-27T10:33:33.148229Z",
     "shell.execute_reply.started": "2021-11-27T10:33:33.085039Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/36700404/tensorflow-opening-log-data-written-by-summarywriter\n",
    "\n",
    "vit_list = []\n",
    "for i in range(5):\n",
    "    print(f\"\\n Fold: {i}==================================================\")\n",
    "    path = [x for x in os.listdir(f\"../input/../input/vit-small/pawnet_lightning_vit_tiny_patch16_224/default/version_{i}/\") if x.startswith(\"events\")][0]\n",
    "    event_acc = EventAccumulator(os.path.join(f\"../input/vit-small/pawnet_lightning_vit_tiny_patch16_224/default/version_{i}/\",path), size_guidance={'scalars': 0})\n",
    "    event_acc.Reload()\n",
    "\n",
    "    scalars = {}\n",
    "    for tag in event_acc.Tags()['scalars']:\n",
    "        events = event_acc.Scalars(tag)\n",
    "        scalars[tag] = [event.value for event in events]\n",
    "    vit_list.append(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T10:33:33.678863Z",
     "iopub.status.busy": "2021-11-27T10:33:33.677808Z",
     "iopub.status.idle": "2021-11-27T10:33:33.685606Z",
     "shell.execute_reply": "2021-11-27T10:33:33.684870Z",
     "shell.execute_reply.started": "2021-11-27T10:33:33.678815Z"
    }
   },
   "outputs": [],
   "source": [
    "vit_val = 0\n",
    "for f in vit_list:\n",
    "    print(f[\"val_RMSE_loss\"][-1])\n",
    "    vit_val +=f[\"val_RMSE_loss\"][-1] / 5\n",
    "print(f\"AVG: {vit_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_0/events.out.tfevents.1638102537.torch.5395.0...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_0/hparams.yaml...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_1/checkpoints/best_loss.ckpt...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_1/checkpoints/last.ckpt...\n",
      "- [4 files][650.0 MiB/650.0 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_1/events.out.tfevents.1638102912.torch.5395.1...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_1/hparams.yaml...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_2/checkpoints/best_loss.ckpt...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_2/checkpoints/last.ckpt...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_2/events.out.tfevents.1638105042.torch.5395.2...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_2/hparams.yaml...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_3/checkpoints/best_loss.ckpt...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_3/checkpoints/last.ckpt...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_3/events.out.tfevents.1638106749.torch.5395.3...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_3/hparams.yaml...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_4/checkpoints/best_loss.ckpt...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_4/checkpoints/last.ckpt...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_4/events.out.tfevents.1638108459.torch.5395.4...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_4/hparams.yaml...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_5/checkpoints/best_loss.ckpt...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_5/checkpoints/last.ckpt...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_5/events.out.tfevents.1638109881.torch.5395.5...\n",
      "Copying gs://pawnet/2d-swin_tiny/pawnet_lightning_swin_tiny4_w7_224/default/version_5/hparams.yaml...\n",
      "\\ [22 files][  3.2 GiB/  3.2 GiB]   50.1 MiB/s                                  \n",
      "Operation completed over 22 objects/3.2 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# ! gsutil cp -r gs://pawnet/2d-swin_tiny/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold: 1==================================================\n",
      "\n",
      " Fold: 2==================================================\n",
      "\n",
      " Fold: 3==================================================\n",
      "\n",
      " Fold: 4==================================================\n",
      "\n",
      " Fold: 5==================================================\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/36700404/tensorflow-opening-log-data-written-by-summarywriter\n",
    "\n",
    "swin_base_list = []\n",
    "for i in range(1,6):\n",
    "    print(f\"\\n Fold: {i}==================================================\")\n",
    "    path = [x for x in os.listdir(f\"pawnet_lightning_swin_tiny4_w7_224/default/version_{i}/\") if x.startswith(\"events\")][0]\n",
    "    event_acc = EventAccumulator(os.path.join(f\"pawnet_lightning_swin_tiny4_w7_224/default/version_{i}/\",path), size_guidance={'scalars': 0})\n",
    "    event_acc.Reload()\n",
    "\n",
    "    scalars = {}\n",
    "    for tag in event_acc.Tags()['scalars']:\n",
    "        events = event_acc.Scalars(tag)\n",
    "        scalars[tag] = [event.value for event in events]\n",
    "    swin_base_list.append(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.600101470947266\n",
      "18.901531219482422\n",
      "18.20035171508789\n",
      "18.23086166381836\n",
      "18.08286476135254\n",
      "AVG: 18.403142166137698\n"
     ]
    }
   ],
   "source": [
    "swin_val = 0\n",
    "count = 0\n",
    "for f in swin_base_list:\n",
    "    print(f[\"val_RMSE_loss\"][-1])\n",
    "    swin_val +=f[\"val_RMSE_loss\"][-1] / 5\n",
    "print(f\"AVG: {swin_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swin + mixup alpha = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold: 0==================================================\n",
      "\n",
      " Fold: 1==================================================\n",
      "\n",
      " Fold: 2==================================================\n",
      "\n",
      " Fold: 3==================================================\n",
      "\n",
      " Fold: 4==================================================\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/36700404/tensorflow-opening-log-data-written-by-summarywriter\n",
    "\n",
    "swin_m02_list = []\n",
    "for i in range(5):\n",
    "    print(f\"\\n Fold: {i}==================================================\")\n",
    "    path = [x for x in os.listdir(f\"pawnet_lightning_swin_tiny4_w7_224_mixup02/default/version_{i}/\") if x.startswith(\"events\")][0]\n",
    "    event_acc = EventAccumulator(os.path.join(f\"pawnet_lightning_swin_tiny4_w7_224_mixup02/default/version_{i}/\",path), size_guidance={'scalars': 0})\n",
    "    event_acc.Reload()\n",
    "\n",
    "    scalars = {}\n",
    "    for tag in event_acc.Tags()['scalars']:\n",
    "        events = event_acc.Scalars(tag)\n",
    "        scalars[tag] = [event.value for event in events]\n",
    "    swin_m02_list.append(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.405834197998047\n",
      "18.675792694091797\n",
      "18.495304107666016\n",
      "18.82900047302246\n",
      "18.1918888092041\n",
      "AVG: 18.519564056396487\n"
     ]
    }
   ],
   "source": [
    "swin_m02_val = 0\n",
    "for f in swin_m02_list:\n",
    "    print(f[\"val_RMSE_loss\"][-1])\n",
    "    swin_m02_val +=f[\"val_RMSE_loss\"][-1] / 5\n",
    "print(f\"AVG: {swin_m02_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swin + mixup alpha = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold: 0==================================================\n",
      "\n",
      " Fold: 1==================================================\n",
      "\n",
      " Fold: 2==================================================\n",
      "\n",
      " Fold: 3==================================================\n",
      "\n",
      " Fold: 4==================================================\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/36700404/tensorflow-opening-log-data-written-by-summarywriter\n",
    "\n",
    "swin_m04_list = []\n",
    "for i in range(5):\n",
    "    print(f\"\\n Fold: {i}==================================================\")\n",
    "    path = [x for x in os.listdir(f\"pawnet_lightning_swin_tiny4_w7_224_mixup04/default/version_{i}/\") if x.startswith(\"events\")][0]\n",
    "    event_acc = EventAccumulator(os.path.join(f\"pawnet_lightning_swin_tiny4_w7_224_mixup04/default/version_{i}/\",path), size_guidance={'scalars': 0})\n",
    "    event_acc.Reload()\n",
    "\n",
    "    scalars = {}\n",
    "    for tag in event_acc.Tags()['scalars']:\n",
    "        events = event_acc.Scalars(tag)\n",
    "        scalars[tag] = [event.value for event in events]\n",
    "    swin_m04_list.append(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.39882469177246\n",
      "18.54518699645996\n",
      "18.29014778137207\n",
      "18.09091567993164\n",
      "17.854639053344727\n",
      "AVG: 18.235942840576172\n"
     ]
    }
   ],
   "source": [
    "swin_m04_val = 0\n",
    "for f in swin_m04_list:\n",
    "    print(f[\"val_RMSE_loss\"][-1])\n",
    "    swin_m04_val +=f[\"val_RMSE_loss\"][-1] / 5\n",
    "print(f\"AVG: {swin_m04_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swin Large + mixup alpha 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold: 5==================================================\n",
      "\n",
      " Fold: 6==================================================\n",
      "\n",
      " Fold: 7==================================================\n",
      "\n",
      " Fold: 8==================================================\n",
      "\n",
      " Fold: 9==================================================\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/36700404/tensorflow-opening-log-data-written-by-summarywriter\n",
    "swinl_m04_list = []\n",
    "for i in range(5,10):\n",
    "    print(f\"\\n Fold: {i}==================================================\")\n",
    "    path = [x for x in os.listdir(f\"pawnet_lightning_swin_large4_w7_224_mixup04/default/version_{i}/\") if x.startswith(\"events\")][0]\n",
    "    event_acc = EventAccumulator(os.path.join(f\"pawnet_lightning_swin_large4_w7_224_mixup04/default/version_{i}/\",path), size_guidance={'scalars': 0})\n",
    "    event_acc.Reload()\n",
    "\n",
    "    scalars = {}\n",
    "    for tag in event_acc.Tags()['scalars']:\n",
    "        events = event_acc.Scalars(tag)\n",
    "        scalars[tag] = [event.value for event in events]\n",
    "    swinl_m04_list.append(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.111711502075195\n",
      "18.313365936279297\n",
      "17.86671257019043\n",
      "17.790376663208008\n",
      "17.887571334838867\n",
      "AVG: 17.99394760131836\n"
     ]
    }
   ],
   "source": [
    "swinl_m04_val = 0\n",
    "for f in swinl_m04_list:\n",
    "    print(f[\"val_RMSE_loss\"][-1])\n",
    "    swinl_m04_val +=f[\"val_RMSE_loss\"][-1] / 5\n",
    "print(f\"AVG: {swinl_m04_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model weights averaging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold: 0==================================================\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "b'pawnet_lightning_swin_large4_w7_224_mixup04/default/version_0/events.out.tfevents.1638533958.torch.2984.0' does not point to valid Events file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31650/1534295975.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n Fold: {i}==================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"swin_tiny4_w7_224_mixup04_swa/default/version_{i}/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"events\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mevent_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEventAccumulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"pawnet_lightning_swin_large4_w7_224_mixup04/default/version_{i}/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_guidance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'scalars'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mevent_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/backend/event_processing/event_accumulator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, size_guidance, compression_bps, purge_orphaned_data)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generator_mutex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_GeneratorFromPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compression_bps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression_bps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/backend/event_processing/event_accumulator.py\u001b[0m in \u001b[0;36m_GeneratorFromPath\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path must be a valid string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mio_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsSummaryEventsFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mevent_file_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLegacyEventFileLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         return directory_watcher.DirectoryWatcher(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/backend/event_processing/event_file_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A file path is required\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplatform_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadahead_file_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_tf_record_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/backend/event_processing/event_file_loader.py\u001b[0m in \u001b[0;36m_make_tf_record_iterator\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Opening a stub record reader pointing at %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         return _PyRecordReaderIterator(\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyRecordReader_New\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# If PyRecordReader exists, use it, otherwise use tf_record_iterator().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/backend/event_processing/event_file_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, py_record_reader_new, file_path)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             self._reader = py_record_reader_new(\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             )\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, start_offset, compression_type, status)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0;34m\"{} does not point to valid Events file\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             )\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: b'pawnet_lightning_swin_large4_w7_224_mixup04/default/version_0/events.out.tfevents.1638533958.torch.2984.0' does not point to valid Events file"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/36700404/tensorflow-opening-log-data-written-by-summarywriter\n",
    "swa_swine_m04_list = []\n",
    "for i in range(2):\n",
    "    print(f\"\\n Fold: {i}==================================================\")\n",
    "    path = [x for x in os.listdir(f\"swin_tiny4_w7_224_mixup04_swa/default/version_{i}/\") if x.startswith(\"events\")][0]\n",
    "    event_acc = EventAccumulator(os.path.join(f\"pawnet_lightning_swin_large4_w7_224_mixup04/default/version_{i}/\",path), size_guidance={'scalars': 0})\n",
    "    event_acc.Reload()\n",
    "\n",
    "    scalars = {}\n",
    "    for tag in event_acc.Tags()['scalars']:\n",
    "        events = event_acc.Scalars(tag)\n",
    "        scalars[tag] = [event.value for event in events]\n",
    "    swa_swine_m04_list.append(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T10:36:08.597121Z",
     "iopub.status.busy": "2021-11-27T10:36:08.596292Z",
     "iopub.status.idle": "2021-11-27T10:36:09.074856Z",
     "shell.execute_reply": "2021-11-27T10:36:09.073595Z",
     "shell.execute_reply.started": "2021-11-27T10:36:08.597057Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=2, figsize=(10,7))\n",
    "fig.suptitle('Logloss Learning Curve - Train')\n",
    "fig.supxlabel('Epochs')\n",
    "fig.supylabel('Logloss')\n",
    "\n",
    "axes[0].set_title(\"Resnet34\")\n",
    "axes[0].plot(np.arange(len(resnet_list[0][\"train_logloss\"])),resnet_list[0][\"train_logloss\"])\n",
    "axes[0].plot(np.arange(len(resnet_list[1][\"train_logloss\"])),resnet_list[1][\"train_logloss\"])\n",
    "axes[0].plot(np.arange(len(resnet_list[2][\"train_logloss\"])),resnet_list[2][\"train_logloss\"])\n",
    "axes[0].plot(np.arange(len(resnet_list[3][\"train_logloss\"])),resnet_list[3][\"train_logloss\"])\n",
    "axes[0].plot(np.arange(len(resnet_list[4][\"train_logloss\"])),resnet_list[4][\"train_logloss\"])\n",
    "axes[0].grid()\n",
    "\n",
    "axes[1].set_title(\"Vit-Tiny-224\")\n",
    "axes[1].plot(np.arange(len(vit_list[0][\"train_logloss\"])),vit_list[0][\"train_logloss\"])\n",
    "axes[1].plot(np.arange(len(vit_list[1][\"train_logloss\"])),vit_list[1][\"train_logloss\"])\n",
    "axes[1].plot(np.arange(len(vit_list[2][\"train_logloss\"])),vit_list[2][\"train_logloss\"])\n",
    "axes[1].plot(np.arange(len(vit_list[3][\"train_logloss\"])),vit_list[3][\"train_logloss\"])\n",
    "axes[1].plot(np.arange(len(vit_list[4][\"train_logloss\"])),vit_list[4][\"train_logloss\"])\n",
    "axes[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T10:39:46.077895Z",
     "iopub.status.busy": "2021-11-27T10:39:46.077579Z",
     "iopub.status.idle": "2021-11-27T10:39:46.555289Z",
     "shell.execute_reply": "2021-11-27T10:39:46.554384Z",
     "shell.execute_reply.started": "2021-11-27T10:39:46.077864Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=2, figsize=(10,7))\n",
    "fig.suptitle('RMSE Learning Curve - Validation')\n",
    "fig.supxlabel('Epochs')\n",
    "fig.supylabel('RMSE')\n",
    "\n",
    "axes[0].set_title(\"Resnet34\")\n",
    "axes[0].plot(np.arange(len(resnet_list[0][\"val_RMSE_loss\"])),resnet_list[0][\"val_RMSE_loss\"])\n",
    "axes[0].plot(np.arange(len(resnet_list[1][\"val_RMSE_loss\"])),resnet_list[1][\"val_RMSE_loss\"])\n",
    "axes[0].plot(np.arange(len(resnet_list[2][\"val_RMSE_loss\"])),resnet_list[2][\"val_RMSE_loss\"])\n",
    "axes[0].plot(np.arange(len(resnet_list[3][\"val_RMSE_loss\"])),resnet_list[3][\"val_RMSE_loss\"])\n",
    "axes[0].plot(np.arange(len(resnet_list[4][\"val_RMSE_loss\"])),resnet_list[4][\"val_RMSE_loss\"])\n",
    "axes[0].grid()\n",
    "\n",
    "axes[1].set_title(\"Vit-Tiny-224\")\n",
    "axes[1].plot(np.arange(len(vit_list[0][\"val_RMSE_loss\"])),vit_list[0][\"val_RMSE_loss\"])\n",
    "axes[1].plot(np.arange(len(vit_list[1][\"val_RMSE_loss\"])),vit_list[1][\"val_RMSE_loss\"])\n",
    "axes[1].plot(np.arange(len(vit_list[2][\"val_RMSE_loss\"])),vit_list[2][\"val_RMSE_loss\"])\n",
    "axes[1].plot(np.arange(len(vit_list[3][\"val_RMSE_loss\"])),vit_list[3][\"val_RMSE_loss\"])\n",
    "axes[1].plot(np.arange(len(vit_list[4][\"val_RMSE_loss\"])),vit_list[4][\"val_RMSE_loss\"])\n",
    "axes[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
