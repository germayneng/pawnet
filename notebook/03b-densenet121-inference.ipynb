{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Inference\n",
    "\n",
    "Because this competition has a hidden test set - we need to set up inference note-book in order to submit our models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisite \n",
    "\n",
    "The additional data have to be added via kaggle's dataset \n",
    "\n",
    "- Petfinder data (test data is unavailable) \n",
    "- attrdictw wheels (../input/attrdictw/attrdict-2.0.1-py2.py3-none-any.whl) \n",
    "- pretrained-model's pth weights (because internet is not available) (import someone's timm-pretrained-weights)\n",
    "- timmaster (for timm ) \n",
    "- add densenet output weights from notebook 2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need for pip because we installed them via dataset ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T14:59:26.907157Z",
     "iopub.status.busy": "2021-11-27T14:59:26.906804Z",
     "iopub.status.idle": "2021-11-27T14:59:26.920782Z",
     "shell.execute_reply": "2021-11-27T14:59:26.919806Z",
     "shell.execute_reply.started": "2021-11-27T14:59:26.907036Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# pip install attrdict\n",
    "# pip install timm\n",
    "# pip install pytorch-lightning==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T14:59:34.246535Z",
     "iopub.status.busy": "2021-11-27T14:59:34.246273Z",
     "iopub.status.idle": "2021-11-27T15:00:04.419894Z",
     "shell.execute_reply": "2021-11-27T15:00:04.418844Z",
     "shell.execute_reply.started": "2021-11-27T14:59:34.246508Z"
    }
   },
   "outputs": [],
   "source": [
    "! pip install ../input/attrdictw/attrdict-2.0.1-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:00:04.428418Z",
     "iopub.status.busy": "2021-11-27T15:00:04.425781Z",
     "iopub.status.idle": "2021-11-27T15:00:04.435338Z",
     "shell.execute_reply": "2021-11-27T15:00:04.434321Z",
     "shell.execute_reply.started": "2021-11-27T15:00:04.428373Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/timmmaster/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:00:35.466689Z",
     "iopub.status.busy": "2021-11-27T15:00:35.466355Z",
     "iopub.status.idle": "2021-11-27T15:00:45.050574Z",
     "shell.execute_reply": "2021-11-27T15:00:45.049562Z",
     "shell.execute_reply.started": "2021-11-27T15:00:35.466662Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from attrdict import AttrDict\n",
    "import torch\n",
    "import yaml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy\n",
    "import pickle\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# additional lightning \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from timm import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:01:37.665134Z",
     "iopub.status.busy": "2021-11-27T15:01:37.664791Z",
     "iopub.status.idle": "2021-11-27T15:01:37.701910Z",
     "shell.execute_reply": "2021-11-27T15:01:37.700601Z",
     "shell.execute_reply.started": "2021-11-27T15:01:37.665091Z"
    }
   },
   "outputs": [],
   "source": [
    "class pawnetDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset\n",
    "    Based on template https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    \"\"\"\n",
    "    def __init__(self,annotation_df, img_dir,transform=None,target_transform=None,test=False,custom_len=None):\n",
    "        self.annotation_df = annotation_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.test=test # if dataset contains labels\n",
    "        self.custom_len=custom_len # if we want to define our own epoch\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Define 1 epoch\"\"\"\n",
    "        if self.custom_len is None:\n",
    "            return len(self.annotation_df)\n",
    "        else:\n",
    "            return self.custom_len\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"called batch num of times\"\"\"\n",
    "        img_path = os.path.join(self.img_dir, self.annotation_df.iloc[idx, 0]) # ID is column index 0\n",
    "        image = read_image(img_path+\".jpg\")\n",
    "        if self.test:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = self.annotation_df.iloc[idx, 13] # Pawpularity is column index 13\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "class pawNetBasic(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    First cut basic pawNet model\n",
    "    we will improve on this - this serves as skeleton code\n",
    "    for other models\n",
    "    \n",
    "    timm contains collection of several pretrained models\n",
    "    \n",
    "    This is a lightning variant *\n",
    "    \n",
    "    \n",
    "    lightning model requires the following methods:\n",
    "    1. forward \n",
    "    2. training_step (logic inside the iteration loop) , validation_step, test_step (not stable on tpu)\n",
    "    3. training_epoch_end, validation_epoch_end\n",
    "    4. configure_optimizers \n",
    "    \n",
    "    other configurable list here https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,criterion, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = 0.2\n",
    "        self._criterion = criterion\n",
    "        self.train_loss = []\n",
    "        self.train_rmse = []\n",
    "        self.valid_rmse = []\n",
    "        \n",
    "        # initialize layers\n",
    "        # https://fastai.github.io/timmdocs/tutorial_feature_extractor\n",
    "        # remove FCL by setting num_classes=0\n",
    "        self.pretrained = create_model(\n",
    "            model_config.pretrained, \n",
    "            pretrained=True, \n",
    "            num_classes=0, \n",
    "            in_chans=3\n",
    "        )\n",
    "#         self.global_avg_pooling = torch.nn.AdaptiveAvgPool2d(1) # timm pretrain comes with pooling\n",
    "        self.linear_1 = torch.nn.Linear(in_features=1024,out_features=1000)\n",
    "        self.prelu = torch.nn.PReLU()\n",
    "        self.linear_2 = torch.nn.Linear(in_features=1000,out_features=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.pretrained(x)\n",
    "#         out = out.view(out.size(0), -1) # reshape for linear. timm already returns with CHW flatten\n",
    "        out = torch.nn.Dropout(self.dropout)(out)\n",
    "        out = self.linear_1(out)\n",
    "        out = self.prelu(out)\n",
    "        out = self.linear_2(out)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        logic instead batch loop\n",
    "        \"\"\"\n",
    "        loss, pred, labels = self.__share_step(batch, 'train')\n",
    "        \n",
    "        return {'loss': loss, 'pred': pred, 'labels': labels}\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        logic instead batch loop for validation\n",
    "        \"\"\"\n",
    "        \n",
    "        loss, pred, labels = self.__share_step(batch, 'val')\n",
    "        return {'loss': loss, 'pred': pred, 'labels': labels}\n",
    "    \n",
    "    def __share_step(self, batch, mode):\n",
    "        images, labels = batch\n",
    "        labels = labels.float() / 100.0\n",
    "        \n",
    "        logits = self.forward(images).squeeze(1)\n",
    "        loss = self._criterion(logits, labels)\n",
    "        \n",
    "        # return logloss for training mode, scaled for others\n",
    "        pred = logits.sigmoid().detach().cpu() * 100.\n",
    "        labels = labels.detach().cpu() * 100.\n",
    "        return loss, pred, labels\n",
    "        \n",
    "    def training_epoch_end(self, outputs):\n",
    "        \"\"\"\n",
    "        called every end of epoch, contains logic\n",
    "        at end of epoch\n",
    "        \"\"\"\n",
    "        self.__share_epoch_end(outputs, mode = 'train')\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.__share_epoch_end(outputs, mode = 'val')    \n",
    "        \n",
    "    def __share_epoch_end(self, outputs, mode):\n",
    "        \"\"\"\n",
    "        output is a list of output defined in\n",
    "        `training_step` as well as `validation_step`.\n",
    "        Need to iterate through each iteration's output.\n",
    "        the output was a dict\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        labels = []\n",
    "        losses = []\n",
    "        for out in outputs:\n",
    "            pred, label, loss = out['pred'], out['labels'], out[\"loss\"]\n",
    "            preds.append(pred)\n",
    "            labels.append(label)\n",
    "            losses.append(loss.view(-1,1))\n",
    "        preds = torch.cat(preds)\n",
    "        labels = torch.cat(labels)\n",
    "        losses = torch.cat(losses)\n",
    "        if mode == \"train\":\n",
    "            loglogss_metrics = losses.mean() # average logloss across iterations\n",
    "            self.log(f'{mode}_logloss', loglogss_metrics, prog_bar=True)\n",
    "        else:\n",
    "            print(f\"{mode}: skip logging for logloss\")\n",
    "            \n",
    "        # RMSE\n",
    "        metrics = torch.sqrt(((labels - preds) ** 2).mean())\n",
    "        # https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html\n",
    "        # automatic accumulation at end of epoch for training, true always for test,validation loops\n",
    "        self.log(f'{mode}_RMSE_loss', metrics, prog_bar=True)\n",
    "        \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.lightning.html#pytorch_lightning.core.lightning.LightningModule.configure_optimizers\n",
    "        \n",
    "        Any of these 6 options.\n",
    "\n",
    "        Single optimizer.\n",
    "\n",
    "        List or Tuple of optimizers.\n",
    "\n",
    "        Two lists - The first list has multiple optimizers, and the second has multiple LR schedulers (or multiple lr_scheduler_config).\n",
    "\n",
    "        Dictionary, with an \"optimizer\" key, and (optionally) a \"lr_scheduler\" key whose value is a single LR scheduler or lr_scheduler_config.\n",
    "\n",
    "        Tuple of dictionaries as described above, with an optional \"frequency\" key.\n",
    "\n",
    "        None - Fit will run without any optimizer.\n",
    "        \"\"\"\n",
    "        #opt = torch.optim.Adam(self.parameters())\n",
    "        # TODO: add learning rate to config\n",
    "        opt = torch.optim.AdamW(self.parameters(),lr=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt,T_0=20,eta_min=1e-4)\n",
    "  \n",
    "        return [opt]\n",
    "\n",
    "\n",
    "\n",
    "def inference_test(model,valid_loader,criterion,device= \"cpu\"):\n",
    "    \"\"\"\n",
    "    performs inference for submission. Note that because\n",
    "    this is test, there is no actual labels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_valid = []\n",
    "    y_pred_valid = []\n",
    "    for i, (x,y) in enumerate(valid_loader):\n",
    "        with torch.no_grad():\n",
    "            pred = model(x.to(device))\n",
    "            pred = torch.sigmoid(pred) * 100.\n",
    "            y_pred_valid.append(pred.squeeze().detach().cpu())\n",
    "            y_valid.append(y.detach().cpu())\n",
    "    # convert from list to tensor\n",
    "    y_valid = torch.cat(y_valid,0)\n",
    "    y_pred_valid = torch.cat(y_pred_valid,0)\n",
    "    if criterion is None:\n",
    "        valid_loss = None\n",
    "    else:\n",
    "        \n",
    "        valid_loss = criterion(y_pred_valid,y_valid).item()\n",
    "    \n",
    "    return valid_loss,y_pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:01:40.190038Z",
     "iopub.status.busy": "2021-11-27T15:01:40.189723Z",
     "iopub.status.idle": "2021-11-27T15:01:40.197850Z",
     "shell.execute_reply": "2021-11-27T15:01:40.196466Z",
     "shell.execute_reply.started": "2021-11-27T15:01:40.190007Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To add to utility.py\n",
    "\"\"\"\n",
    "\n",
    "# def seed_everything(seed=1234):\n",
    "#     \"\"\"\n",
    "#     Utility function to seed everything\n",
    "#     source: https://www.kaggle.com/bminixhofer/deterministic-neural-networks-using-pytorch\n",
    "#     \"\"\"\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    \n",
    "\n",
    "def read_yaml(filename):\n",
    "    \"\"\"\n",
    "    Read yaml configuation and returns the dict\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: string\n",
    "        Path including yaml file name\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "    \n",
    "# configs\n",
    "\n",
    "# config is different in kaggle\n",
    "\n",
    "\n",
    "class BaseConfigLoader:\n",
    "    \n",
    "    def __init__(self,config_path):\n",
    "        self.config = read_yaml(config_path)\n",
    "            \n",
    "    def load_config(self):\n",
    "        return AttrDict(self.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:02:39.820550Z",
     "iopub.status.busy": "2021-11-27T15:02:39.819991Z",
     "iopub.status.idle": "2021-11-27T15:02:39.856279Z",
     "shell.execute_reply": "2021-11-27T15:02:39.855333Z",
     "shell.execute_reply.started": "2021-11-27T15:02:39.820514Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is specific to kaggle\n",
    "# if running in GCS, replace with our GCP bucket \n",
    "# get cache location of the dataset \n",
    "# GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
    "base_config_manager = BaseConfigLoader(\"../input/config/config.yaml\")\n",
    "\n",
    "# set config based on model \n",
    "model_config = base_config_manager.model.densenet121\n",
    "\n",
    "file_path = base_config_manager.load_config().filepath.kaggle #\"/kaggle/input/petfinder-pawpularity-score/\"\n",
    "test_df = pd.read_csv(os.path.join(file_path,\"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:02:41.581876Z",
     "iopub.status.busy": "2021-11-27T15:02:41.581599Z",
     "iopub.status.idle": "2021-11-27T15:02:41.588987Z",
     "shell.execute_reply": "2021-11-27T15:02:41.588013Z",
     "shell.execute_reply.started": "2021-11-27T15:02:41.581846Z"
    }
   },
   "outputs": [],
   "source": [
    "test_transformation = T.Compose([\n",
    "                T.Resize([224,224]),# imgnet needs at least 224\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n",
    "                ]\n",
    "            )\n",
    "\n",
    "\n",
    "test_data = pawnetDataset(annotation_df=test_df,img_dir =os.path.join(file_path,\"test\"), transform = test_transformation,test=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,batch_size=64,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weights and inference\n",
    "\n",
    "https://pytorch-lightning.readthedocs.io/en/latest/common/weights_loading.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:05:26.000574Z",
     "iopub.status.busy": "2021-11-27T15:05:26.000286Z",
     "iopub.status.idle": "2021-11-27T15:05:26.006287Z",
     "shell.execute_reply": "2021-11-27T15:05:26.004791Z",
     "shell.execute_reply.started": "2021-11-27T15:05:26.000530Z"
    }
   },
   "outputs": [],
   "source": [
    "# create model and load checkpoint \n",
    "\n",
    "# load config\n",
    "# this object manages all the configurations\n",
    "\n",
    "# base_config_manager = BaseConfigLoader(\"../input/config/config.yaml\")\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:05:26.389863Z",
     "iopub.status.busy": "2021-11-27T15:05:26.389498Z",
     "iopub.status.idle": "2021-11-27T15:05:49.052895Z",
     "shell.execute_reply": "2021-11-27T15:05:49.050298Z",
     "shell.execute_reply.started": "2021-11-27T15:05:26.389835Z"
    }
   },
   "outputs": [],
   "source": [
    "# load and weights - will fail hre because no internet\n",
    "try:\n",
    "    model = pawNetBasic.load_from_checkpoint(checkpoint_path=f\"../input/02b-densenet121/pawnet_lightning_densenet/default/version_0/checkpoints/best_loss.ckpt\",criterion=criterion)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"no internet... cannot download weights... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:05:54.717306Z",
     "iopub.status.busy": "2021-11-27T15:05:54.716296Z",
     "iopub.status.idle": "2021-11-27T15:05:56.683695Z",
     "shell.execute_reply": "2021-11-27T15:05:56.682167Z",
     "shell.execute_reply.started": "2021-11-27T15:05:54.717254Z"
    }
   },
   "outputs": [],
   "source": [
    "# copy weights to torch cache\n",
    "\n",
    "! cp ../input/timm-pretrained-weights/densenet121_ra-50efcf5c.pth /root/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:06:30.436551Z",
     "iopub.status.busy": "2021-11-27T15:06:30.436221Z",
     "iopub.status.idle": "2021-11-27T15:06:51.880600Z",
     "shell.execute_reply": "2021-11-27T15:06:51.879391Z",
     "shell.execute_reply.started": "2021-11-27T15:06:30.436505Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# predict\n",
    "# create empty array\n",
    "pred_all = np.zeros(len(test_df))\n",
    "\n",
    "# loop over folds \n",
    "for i in range(5):\n",
    "    print(f\"Loading fold {i} weights and perform inference\")\n",
    "    model = pawNetBasic.load_from_checkpoint(checkpoint_path=f\"../input/02b-densenet121/pawnet_lightning_densenet/default/version_{i}/checkpoints/best_loss.ckpt\",criterion=criterion)\n",
    "    model = model.to(\"cuda\")\n",
    "    _,pred = inference_test(model,test_loader,criterion=None,device=\"cuda\")\n",
    "    pred_all += pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:06:55.905013Z",
     "iopub.status.busy": "2021-11-27T15:06:55.903968Z",
     "iopub.status.idle": "2021-11-27T15:06:55.923672Z",
     "shell.execute_reply": "2021-11-27T15:06:55.922523Z",
     "shell.execute_reply.started": "2021-11-27T15:06:55.904968Z"
    }
   },
   "outputs": [],
   "source": [
    "# create submission\n",
    "sub = test_df[[\"Id\"]]\n",
    "sub[\"Pawpularity\"] = pred_all / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:06:56.853999Z",
     "iopub.status.busy": "2021-11-27T15:06:56.853439Z",
     "iopub.status.idle": "2021-11-27T15:06:56.875605Z",
     "shell.execute_reply": "2021-11-27T15:06:56.874753Z",
     "shell.execute_reply.started": "2021-11-27T15:06:56.853967Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T15:06:59.498214Z",
     "iopub.status.busy": "2021-11-27T15:06:59.497850Z",
     "iopub.status.idle": "2021-11-27T15:06:59.511515Z",
     "shell.execute_reply": "2021-11-27T15:06:59.509980Z",
     "shell.execute_reply.started": "2021-11-27T15:06:59.498182Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
