{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ba13d0-efbf-4ac1-aae1-5521f51f871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from attrdict import AttrDict\n",
    "import torch\n",
    "import yaml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy\n",
    "import pickle\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# additional lightning \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from timm import create_model\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3036e237-1294-46e8-97a0-0907330750ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# VM USE THIS\n",
    "##################\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from pawnet.utility import *\n",
    "\n",
    "\n",
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "# you need to import the utility script by uploading to kaggle as pawnet_utility/pawnet_utility.py\n",
    "# from pawnet_utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "372020e8-ab31-4bc2-a973-680ff0df235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra augmentations for experiments\n",
    "import pawnet.augmentations as aug_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9560a79-3515-48b1-b28c-e6b67fd3ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "# this object manages all the configurations\n",
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "# config_path = \"../input/config/config.yaml\"\n",
    "\n",
    "##################\n",
    "# VM USE THIS\n",
    "##################\n",
    "config_path = \"../config/config.yaml\"\n",
    "base_config_manager = BaseConfigLoader(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8068f224-789c-4685-ac57-585989da88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "# this is specific to kaggle\n",
    "# if running in GCS, replace with our GCP bucket\n",
    "# get cache location of the dataset\n",
    "# GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
    "# file_path = base_config_manager.load_config().filepath.kaggle #\"/kaggle/input/petfinder-pawpularity-score/\"\n",
    "\n",
    "\n",
    "##################\n",
    "# VM USE THIS\n",
    "##################\n",
    "file_path = base_config_manager.load_config().filepath.gcs\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(file_path,\"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(file_path,\"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78d86f8-0921-457a-ad48-385cf83d3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iterate model.named_children() instead of children())- https://medium.com/the-dl/how-to-use-pytorch-hooks-5041d777f904 \n",
    "class featureExtractor:\n",
    "    \"\"\"\n",
    "    Extracts feature maps/activate maps from various model\n",
    "    \"\"\"\n",
    "    def get_activation_map(self,x_in, model,model_type=\"swin\"):\n",
    "        \"\"\"\n",
    "        add forward hook to the last output of swin transformer sequential block\n",
    "        \"\"\"\n",
    "        \n",
    "        # get last feature map from model.pretrained\n",
    "        feature_map_mod = self.get_module_chidren(model=model,model_type=model_type)\n",
    "        \n",
    "        self.activation_value = None  # Stores the activation of the module you chose above during a forwards pass.\n",
    "        def activation_hook(a, b, activation):\n",
    "            self.activation_value = activation\n",
    "        \n",
    "        feature_map_mod.register_forward_hook(activation_hook)\n",
    "        \n",
    "        # forward\n",
    "        model.eval()\n",
    "        score = model(x_in)\n",
    "        self.score = score\n",
    "        \n",
    "    def get_module_chidren(self,model,model_type=\"swin\"):\n",
    "        \"\"\"\n",
    "        Helper method to get last featuremap module depending on the architecture\n",
    "        \"\"\"\n",
    "        \n",
    "        # index depending on model:\n",
    "        if model_type == \"swin\":\n",
    "            last_feature_index = 3\n",
    "        elif model_type == \"resnet34\":\n",
    "            last_feature_index = 7\n",
    "        elif model_type == \"densenet\":\n",
    "            last_feature_index = 0\n",
    "        elif model_type == \"efficientnet\":\n",
    "            last_feature_index = 6\n",
    "        elif model_type == \"vit_small\":\n",
    "            last_feature_index = 2\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i,param in enumerate(model.pretrained.children()):\n",
    "            if i == last_feature_index:\n",
    "                feature_map_mod = param\n",
    "        \n",
    "        return feature_map_mod    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ce48a-99fa-47de-9ccc-5da3fc282ae4",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7084d1-a8fd-4605-a1b7-6ea240159e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting: fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model_config = base_config_manager.load_config().model.swin_tiny4_w7_224_cut1 # for general skf config\n",
    "test_transformation = T.Compose([\n",
    "                T.Resize([224,224]),# imgnet needs at least 224\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n",
    "                ]\n",
    "            )\n",
    "\n",
    "seed_everything(1)\n",
    "skf = StratifiedKFold(n_splits = model_config.n_splits, shuffle = True, random_state = 1)\n",
    "splits = skf.split(train_df[\"Id\"],train_df[\"Pawpularity\"])\n",
    "\n",
    "rmse_list = []\n",
    "\n",
    "# get data loader for fold 0\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    print(\"\\n Starting: fold {}\".format(i+1))\n",
    "    X_train, X_valid = train_df.iloc[train_index], train_df.iloc[test_index]\n",
    "    X_train.reset_index(inplace=True,drop=True)\n",
    "    X_valid.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    valid_data = pawnetDataset(annotation_df=X_valid,img_dir =os.path.join(file_path,\"train\"), transform = test_transformation,test=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data,batch_size=64,shuffle=False,num_workers=2)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c238bd01-4c1c-415d-a830-5577a28986e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first batch of data\n",
    "x_1,y_1 = iter(valid_loader).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d05c5-285e-49de-999f-f2672392cddc",
   "metadata": {},
   "source": [
    "For the following sections, you need to run separately and not in 1 single run - else kernel will get error and die"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5329a8-1cbd-4e15-b14d-277d6f4e29c5",
   "metadata": {},
   "source": [
    "# Load Swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6bd9ae0-ffcc-48d4-98c4-b5ce16c6b1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will perform cutmix\n"
     ]
    }
   ],
   "source": [
    "model_config = base_config_manager.load_config().model.swin_tiny4_w7_224_cut1\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "swin_model = pawNetBasic.load_from_checkpoint(checkpoint_path=f\"pawnet_lightning_swin_tiny4_w7_224_mixup04/default/version_0/checkpoints/best_loss.ckpt\",criterion=criterion,model_config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58939d13-9ffd-4200-a9a0-3f86a5f0158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = featureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced1cd1e-3a27-4e92-bdad-fb64dce5c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.get_activation_map(x_in=x_1,model=swin_model,model_type=\"swin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7c4855-ac72-44dc-b2c3-b12291f30573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 49, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.activation_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c566672e-026a-4a7e-a97f-8ed74556ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "swin_feature_map = fe.activation_value.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6d34bca-1406-4cc5-8bc8-d8989663cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del fe, swin_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92f789a4-b573-4cb9-a562-3babcae5ed4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f41cc1b5-f789-4f39-96b7-069cd2da4f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"swin.pkl\",\"wb\") as fout:\n",
    "    pickle.dump([swin_feature_map],fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f42e1a-a563-46e4-bab4-e543dba9a27c",
   "metadata": {},
   "source": [
    "# Load Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203b7040-9434-4a1c-81d4-a18aedeccc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = base_config_manager.load_config().model.densenet121\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "densenet_model = pawNetBasic.load_from_checkpoint(checkpoint_path=f\"pawnet_lightning_densenet/default/version_0/checkpoints/best_loss.ckpt\",criterion=criterion,model_config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd30457e-4ddf-42a0-992a-27287c5b51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_fe = featureExtractor()\n",
    "dense_fe.get_activation_map(x_in=x_1,model=densenet_model,model_type=\"densenet\")\n",
    "denset_feature_map = dense_fe.activation_value.clone()\n",
    "\n",
    "del dense_fe, densenet_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with open(\"densenet.pkl\",\"wb\") as fout:\n",
    "    pickle.dump([denset_feature_map],fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53cd641-e890-4ea5-859d-5439894006a5",
   "metadata": {},
   "source": [
    "# Load EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f36001-a145-4742-b400-496a0a4c8e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = base_config_manager.load_config().model.efficientnet_b0\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "effnet_model = pawNetBasic.load_from_checkpoint(checkpoint_path=f\"pawnet_lightning_efficientnet_b0/default/version_0/checkpoints/best_loss.ckpt\",criterion=criterion,model_config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f225f1c-d353-4743-88dd-c07c3265a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_fe = featureExtractor()\n",
    "eff_fe.get_activation_map(x_in=x_1,model=effnet_model,model_type=\"efficientnet\")\n",
    "eff_feature_map = eff_fe.activation_value.clone()\n",
    "\n",
    "del eff_fe, effnet_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with open(\"efficientnet.pkl\",\"wb\") as fout:\n",
    "    pickle.dump([eff_feature_map],fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee4736-1963-48dc-98ca-c1131245875b",
   "metadata": {},
   "source": [
    "# Load Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f893de36-ec05-4526-8d7c-7e2ef187acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34-43635321.pth\" to /home/jupyter/.cache/torch/hub/checkpoints/resnet34-43635321.pth\n"
     ]
    }
   ],
   "source": [
    "model_config = base_config_manager.load_config().model.resnet34\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "resnet_model = pawNetBasic.load_from_checkpoint(checkpoint_path=f\"02a-resnet/pawnet_lightning_resnet/default/version_0/checkpoints/best_loss.ckpt\",criterion=criterion,model_config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb6b2e9e-f3b2-4f04-a05e-4fee06279f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_fe = featureExtractor()\n",
    "resnet_fe.get_activation_map(x_in=x_1,model=resnet_model,model_type=\"resnet34\")\n",
    "resnet_feature_map = resnet_fe.activation_value.clone()\n",
    "\n",
    "with open(\"resnet.pkl\",\"wb\") as fout:\n",
    "    pickle.dump([resnet_feature_map],fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b7f638-a3f2-45a1-8f90-3b4195246f95",
   "metadata": {},
   "source": [
    "# load vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e657ebdf-9f08-45b7-931b-d42040064921",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = base_config_manager.load_config().model.vit_tiny16_224\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "vit_model = pawNetBasic.load_from_checkpoint(checkpoint_path=f\"02c-vit-small/pawnet_lightning_vit_tiny_patch16_224/default/version_0/checkpoints/best_loss.ckpt\",criterion=criterion,model_config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aaddb3d-68db-4900-b4bf-d08ba9c07704",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_fe = featureExtractor()\n",
    "vit_fe.get_activation_map(x_in=x_1,model=vit_model,model_type=\"vit_small\")\n",
    "vit_feature_map = vit_fe.activation_value.clone()\n",
    "\n",
    "with open(\"vit_small.pkl\",\"wb\") as fout:\n",
    "    pickle.dump([vit_feature_map],fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676582d-3b2a-4b9e-89f6-d914a6eb6898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
