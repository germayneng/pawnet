{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nimport matplotlib.pyplot as plt\nimport os\nimport tqdm\n\nimport seaborn as sns\nfrom torchvision.io import read_image\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\nfrom attrdict import AttrDict\nimport torch\nimport yaml\nfrom sklearn.model_selection import StratifiedKFold\nimport copy\nimport pickle\n# from tqdm import tqdm_notebook\n\n# additional lightning \n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule\n\n\n# pytorch\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom timm import create_model\n\n\nfrom utility import *","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:35:17.105207Z","iopub.execute_input":"2021-12-11T17:35:17.105559Z","iopub.status.idle":"2021-12-11T17:35:17.135146Z","shell.execute_reply.started":"2021-12-11T17:35:17.105523Z","shell.execute_reply":"2021-12-11T17:35:17.134373Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:35:17.147432Z","iopub.execute_input":"2021-12-11T17:35:17.147961Z","iopub.status.idle":"2021-12-11T17:35:17.176022Z","shell.execute_reply.started":"2021-12-11T17:35:17.147918Z","shell.execute_reply":"2021-12-11T17:35:17.175233Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test_transformation = T.Compose([\n                T.Resize([224,224]),# imgnet needs at least 224\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n                ]\n            )","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:35:18.257426Z","iopub.execute_input":"2021-12-11T17:35:18.258087Z","iopub.status.idle":"2021-12-11T17:35:18.265572Z","shell.execute_reply.started":"2021-12-11T17:35:18.258046Z","shell.execute_reply":"2021-12-11T17:35:18.264588Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Load weights and inference\n\nhttps://pytorch-lightning.readthedocs.io/en/latest/common/weights_loading.html","metadata":{}},{"cell_type":"code","source":"import torchvision\nfrom torchvision import models\n\ncriterion = torch.nn.BCEWithLogitsLoss()\n\ni=0\n#model = pawNetBasic.load_from_checkpoint(checkpoint_path=f\"../input/pawnet-ans/paw_greater0_pseudo-labeling_pawpularity__version_{i}_checkpoints_best_loss.ckpt\",criterion=criterion,model_config=model_config)\nmodel = models.resnet18(pretrained=True)\n\n#model = model.to(\"cuda\")\nmodel = model.eval()\n\nimg_path = '../input/petfinder-pawpularity-score/train/0007de18844b0dbbb5e1f607da0606e0.jpg'\nwith open(img_path, 'rb') as f:\n    img = Image.open(f)\n    img = (img).convert(\"RGB\")\n    img = T.ToTensor()(img)\n    f.close()\n\ninput = test_transformation(img)\n\ninput = input.unsqueeze(0)\n\noutput = model(input)\noutput = F.softmax(output, dim=1)\nprediction_score, pred_label_idx = torch.topk(output, 1)\n\npred_label_idx.squeeze_(), prediction_score.squeeze().item()\n#predicted_label = idx_to_labels[str(pred_label_idx.item())][1]\n#print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:35:26.424572Z","iopub.execute_input":"2021-12-11T17:35:26.425336Z","iopub.status.idle":"2021-12-11T17:35:26.882742Z","shell.execute_reply.started":"2021-12-11T17:35:26.425293Z","shell.execute_reply":"2021-12-11T17:35:26.881986Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"\"\"\"saliency maps\"\"\"\n!pip install captum \n\nfrom captum.attr import IntegratedGradients\nfrom captum.attr import GradientShap\nfrom captum.attr import Saliency\nfrom captum.attr import NoiseTunnel\nfrom captum.attr import visualization as viz\n\nimport torch\nimport torch.nn.functional as F\n\nfrom PIL import Image\n\nimport os\nimport json\nimport numpy as np\nfrom matplotlib.colors import LinearSegmentedColormap\n\nfrom captum.attr import Saliency\n\ndef attribute_image_features(algorithm, input, **kwargs):\n    net.zero_grad()\n    tensor_attributions = algorithm.attribute(input,\n                                              target=labels[ind],\n                                              **kwargs\n                                             )\n    \n    return tensor_attributions\n\nsaliency = Saliency(model)\ngrads = saliency.attribute(input, target=0)\ngrads = np.transpose(grads.squeeze().cpu().detach().numpy(), (1, 2, 0))\n\n\n_ = viz.visualize_image_attr(None, np.transpose(input.squeeze().cpu().detach().numpy(), (1,2,0)), \n                      method=\"original_image\", title=\"Original Image\")\n\n_ = viz.visualize_image_attr(grads, np.transpose(input.squeeze().cpu().detach().numpy(), (1,2,0)), method=\"blended_heat_map\", sign=\"absolute_value\",\n                          show_colorbar=True, title=\"Overlayed Gradient Magnitudes\")","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:45:09.946251Z","iopub.execute_input":"2021-12-11T17:45:09.947230Z","iopub.status.idle":"2021-12-11T17:45:18.676103Z","shell.execute_reply.started":"2021-12-11T17:45:09.947181Z","shell.execute_reply":"2021-12-11T17:45:18.675319Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from captum.attr import LayerGradCam\nimport skimage.transform\n\nlayer_gc = LayerGradCam(model, model.layer4[1].conv2)\n\n# get for each class \nattr_1 = layer_gc.attribute(input, 1, relu_attributions=True)\npred = model(input)\n\nplt.imshow(np.transpose(input.squeeze().cpu().detach().numpy(), (1,2,0)))\nplt.imshow(skimage.transform.resize(attr_1.detach().cpu().numpy()[0][0], (224,224)), alpha=0.5, cmap='jet')\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-12-11T18:04:06.977433Z","iopub.execute_input":"2021-12-11T18:04:06.978051Z","iopub.status.idle":"2021-12-11T18:04:07.277160Z","shell.execute_reply.started":"2021-12-11T18:04:06.977993Z","shell.execute_reply":"2021-12-11T18:04:07.276440Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"_ = viz.visualize_image_attr(None, np.transpose(input.squeeze().cpu().detach().numpy(), (1,2,0)),\n                      method=\"original_image\", title=\"Original Image\")","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:41:15.818983Z","iopub.execute_input":"2021-12-11T17:41:15.820034Z","iopub.status.idle":"2021-12-11T17:41:16.058909Z","shell.execute_reply.started":"2021-12-11T17:41:15.819971Z","shell.execute_reply":"2021-12-11T17:41:16.058259Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_df.iloc[0].Pawpularity","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:31:38.280503Z","iopub.execute_input":"2021-12-11T17:31:38.281144Z","iopub.status.idle":"2021-12-11T17:31:38.297776Z","shell.execute_reply.started":"2021-12-11T17:31:38.281098Z","shell.execute_reply":"2021-12-11T17:31:38.297064Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install captum \n\nfrom captum.attr import IntegratedGradients\nfrom captum.attr import GradientShap\nfrom captum.attr import Saliency\nfrom captum.attr import NoiseTunnel\nfrom captum.attr import visualization as viz\n\nimport torch\nimport torch.nn.functional as F\n\nfrom PIL import Image\n\nimport os\nimport json\nimport numpy as np\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Create IntegratedGradients object and get attributes\nintegrated_gradients = IntegratedGradients(model)\nattributions_ig = integrated_gradients.attribute(input, target=pred_label_idx, n_steps=200)\n\n# create custom colormap for visualizing the result\ndefault_cmap = LinearSegmentedColormap.from_list('custom blue', \n                                                 [(0, '#ffffff'),\n                                                  (0.25, '#000000'),\n                                                  (1, '#000000')], N=256)\n\n\n# visualize the results using the visualize_image_attr helper method\n_ = viz.visualize_image_attr_multiple(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n                             np.transpose(img.squeeze().cpu().detach().numpy(), (1,2,0)),\n                             methods=[\"original_image\", \"heat_map\"],\n                             signs=['all', 'positive'],\n                             cmap=default_cmap,\n                             show_colorbar=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:27:11.886941Z","iopub.execute_input":"2021-12-11T17:27:11.887241Z"},"trusted":true},"execution_count":null,"outputs":[]}]}