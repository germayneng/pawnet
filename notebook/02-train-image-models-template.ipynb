{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training image-based models as baseline\n",
    "\n",
    "\n",
    "General instructions: \n",
    "\n",
    "Fork this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T07:53:59.646881Z",
     "iopub.status.busy": "2021-11-28T07:53:59.646362Z",
     "iopub.status.idle": "2021-11-28T07:54:23.702682Z",
     "shell.execute_reply": "2021-11-28T07:54:23.701838Z",
     "shell.execute_reply.started": "2021-11-28T07:53:59.646788Z"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "# %%bash\n",
    "# # for kaggle only \n",
    "# pip install attrdict\n",
    "# pip install timm\n",
    "# pip install pytorch-lightning==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-28T07:54:28.592972Z",
     "iopub.status.busy": "2021-11-28T07:54:28.592346Z",
     "iopub.status.idle": "2021-11-28T07:54:35.566050Z",
     "shell.execute_reply": "2021-11-28T07:54:35.565282Z",
     "shell.execute_reply.started": "2021-11-28T07:54:28.592932Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from attrdict import AttrDict\n",
    "import torch\n",
    "import yaml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy\n",
    "import pickle\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# additional lightning \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from timm import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T07:54:35.567997Z",
     "iopub.status.busy": "2021-11-28T07:54:35.567764Z",
     "iopub.status.idle": "2021-11-28T07:54:35.581438Z",
     "shell.execute_reply": "2021-11-28T07:54:35.580435Z",
     "shell.execute_reply.started": "2021-11-28T07:54:35.567965Z"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# VM USE THIS\n",
    "##################\n",
    "# import utility (this is for kaggle kernel)\n",
    "# if you are in actual notebook use this -----\n",
    "# import sys\n",
    "# sys.path.append(\"../\")\n",
    "# from pawnet.utility import *\n",
    "\n",
    "\n",
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "# you need to import the utility script by uploading to kaggle as pawnet_utility/pawnet_utility.py\n",
    "from pawnet_utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T07:54:35.582992Z",
     "iopub.status.busy": "2021-11-28T07:54:35.582717Z",
     "iopub.status.idle": "2021-11-28T07:54:35.594879Z",
     "shell.execute_reply": "2021-11-28T07:54:35.594153Z",
     "shell.execute_reply.started": "2021-11-28T07:54:35.582957Z"
    }
   },
   "outputs": [],
   "source": [
    "# # check the package version to get reproducible env \n",
    "# # source: https://www.kaggle.com/rtatman/get-the-versions-of-imported-packages\n",
    "\n",
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "\n",
    "# import pkg_resources\n",
    "# import types\n",
    "# def get_imports():\n",
    "#     for name, val in globals().items():\n",
    "#         if isinstance(val, types.ModuleType):\n",
    "#             # Split ensures you get root package, \n",
    "#             # not just imported function\n",
    "#             name = val.__name__.split(\".\")[0]\n",
    "\n",
    "#         elif isinstance(val, type):\n",
    "#             name = val.__module__.split(\".\")[0]\n",
    "\n",
    "#         # Some packages are weird and have different\n",
    "#         # imported names vs. system names\n",
    "#         if name == \"PIL\":\n",
    "#             name = \"Pillow\"\n",
    "#         elif name == \"sklearn\":\n",
    "#             name = \"scikit-learn\"\n",
    "\n",
    "#         yield name\n",
    "# imports = list(set(get_imports()))\n",
    "\n",
    "# requirements = []\n",
    "# for m in pkg_resources.working_set:\n",
    "#     if m.project_name in imports and m.project_name!=\"pip\":\n",
    "#         requirements.append((m.project_name, m.version))\n",
    "\n",
    "# for r in requirements:\n",
    "#     print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T07:54:35.597115Z",
     "iopub.status.busy": "2021-11-28T07:54:35.596552Z",
     "iopub.status.idle": "2021-11-28T07:54:35.616785Z",
     "shell.execute_reply": "2021-11-28T07:54:35.616155Z",
     "shell.execute_reply.started": "2021-11-28T07:54:35.597076Z"
    }
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "# this object manages all the configurations\n",
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "config_path = \"../input/config/config.yaml\"\n",
    "\n",
    "##################\n",
    "# VM USE THIS\n",
    "##################\n",
    "# config_path = \"../config/config.yaml\"\n",
    "\n",
    "\n",
    "base_config_manager = BaseConfigLoader(config_path)\n",
    "\n",
    "# TODO: edit this for each base image model\n",
    "model_config = base_config_manager.load_config().model.efficientnet_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T07:54:35.617975Z",
     "iopub.status.busy": "2021-11-28T07:54:35.617716Z",
     "iopub.status.idle": "2021-11-28T07:54:35.625429Z",
     "shell.execute_reply": "2021-11-28T07:54:35.624733Z",
     "shell.execute_reply.started": "2021-11-28T07:54:35.617942Z"
    }
   },
   "outputs": [],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "We will load the data by creating torch datasets as well as dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T07:54:35.627330Z",
     "iopub.status.busy": "2021-11-28T07:54:35.626517Z",
     "iopub.status.idle": "2021-11-28T07:54:35.670918Z",
     "shell.execute_reply": "2021-11-28T07:54:35.670266Z",
     "shell.execute_reply.started": "2021-11-28T07:54:35.627295Z"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "# this is specific to kaggle\n",
    "# if running in GCS, replace with our GCP bucket \n",
    "# get cache location of the dataset \n",
    "# GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
    "# file_path = base_config_manager.load_config().filepath.kaggle #\"/kaggle/input/petfinder-pawpularity-score/\"\n",
    "\n",
    "##################\n",
    "# VM USE THIS\n",
    "##################\n",
    "file_path = base_config_manager.load_config().filepath.gcs\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(file_path,\"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(file_path,\"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T07:54:35.673585Z",
     "iopub.status.busy": "2021-11-28T07:54:35.673077Z",
     "iopub.status.idle": "2021-11-28T07:54:35.696401Z",
     "shell.execute_reply": "2021-11-28T07:54:35.695752Z",
     "shell.execute_reply.started": "2021-11-28T07:54:35.673554Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T07:54:40.840082Z",
     "iopub.status.busy": "2021-11-28T07:54:40.839818Z",
     "iopub.status.idle": "2021-11-28T07:54:40.853247Z",
     "shell.execute_reply": "2021-11-28T07:54:40.852606Z",
     "shell.execute_reply.started": "2021-11-28T07:54:40.840053Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train basic models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for training - lightning variant \n",
    "\n",
    "* create relevant transformations, validation splits\n",
    "* what this version differs is that we will be using the pytorch lightning framework - this allows easy TPU access for training \n",
    "\n",
    "lightning walkthrough: \n",
    "https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction_guide.html\n",
    "<br>\n",
    "https://devblog.pytorchlightning.ai/train-anything-with-lightning-custom-loops-4be32314c961\n",
    "<br>\n",
    "https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/loop_examples/mnist_lite.py\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T07:54:44.922152Z",
     "iopub.status.busy": "2021-11-28T07:54:44.921609Z",
     "iopub.status.idle": "2021-11-28T07:54:44.931118Z",
     "shell.execute_reply": "2021-11-28T07:54:44.930306Z",
     "shell.execute_reply.started": "2021-11-28T07:54:44.922113Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All pre-trained models expect input images normalized in the same way, \n",
    "i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), \n",
    "where H and W are expected to be at least 224. \n",
    "The images have to be loaded in to a range of [0, 1] and then \n",
    "normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. \n",
    "You can use the following transform to normalize:\n",
    "\n",
    "https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "\"\"\"\n",
    "train_transformation = T.Compose(\n",
    "            [\n",
    "                T.Resize([224,224]),# imgnet needs at least 224\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.RandomVerticalFlip(),\n",
    "                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n",
    "            ]\n",
    "        )\n",
    "# train_data = pawnetDataset(annotation_df=train_df,img_dir = os.path.join(file_path,\"train\"),transform = train_transformation)\n",
    "# # batchsize should be parameter in config\n",
    "# train_loader = torch.utils.data.DataLoader(train_data,batch_size=64,num_workers =2, shuffle=True)\n",
    "\n",
    "\n",
    "test_transformation = T.Compose([\n",
    "                T.Resize([224,224]),# imgnet needs at least 224\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:12:54.120832Z",
     "iopub.status.busy": "2021-11-22T13:12:54.119896Z",
     "iopub.status.idle": "2021-11-22T13:12:54.127352Z",
     "shell.execute_reply": "2021-11-22T13:12:54.125898Z",
     "shell.execute_reply.started": "2021-11-22T13:12:54.120797Z"
    }
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T07:54:47.893029Z",
     "iopub.status.busy": "2021-11-28T07:54:47.892733Z",
     "iopub.status.idle": "2021-11-28T07:55:23.525424Z",
     "shell.execute_reply": "2021-11-28T07:55:23.524055Z",
     "shell.execute_reply.started": "2021-11-28T07:54:47.892998Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(1)\n",
    "\n",
    "\n",
    "# perfrom stratified sampling k fold model training\n",
    "skf = StratifiedKFold(n_splits = model_config.n_splits, shuffle = True, random_state = 1)\n",
    "splits = skf.split(train_df[\"Id\"],train_df[\"Pawpularity\"])\n",
    "\n",
    "\n",
    "skf_train_list = [] # to store across folds\n",
    "skf_valid_list = [] # to store across folds\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    print(\"\\n Starting: fold {}\".format(i+1))\n",
    "    \n",
    "    # initialize model \n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    X_train, X_valid = train_df.iloc[train_index], train_df.iloc[test_index]\n",
    "    X_train.reset_index(inplace=True,drop=True)\n",
    "    X_valid.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    # build datamodule\n",
    "    datamodule = PetfinderDataModule(img_dir = os.path.join(file_path,\"train\"),\n",
    "                                     train_df=X_train,\n",
    "                                     val_df=X_valid,\n",
    "                                     train_transformation=train_transformation,\n",
    "                                     test_transformation=test_transformation,\n",
    "                                     batch_size=model_config.batch_size,\n",
    "                                     num_workers=model_config.num_workers)\n",
    "    \n",
    "    \n",
    "    model = pawNetBasic(criterion=criterion,model_config=model_config)\n",
    "    print(model.summarize())\n",
    "    earystopping = EarlyStopping(monitor=\"val_RMSE_loss\",patience=5)\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=\"best_loss\",\n",
    "        monitor=\"val_RMSE_loss\",\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "        save_last=True,\n",
    "    )\n",
    "    logger = TensorBoardLogger(model_config.model_name)\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger, # tensorboard logger\n",
    "        max_epochs=model_config.epoch,\n",
    "        callbacks=[lr_monitor, loss_checkpoint, earystopping],\n",
    "#          callbacks=[lr_monitor, loss_checkpoint],\n",
    "         gpus=1,progress_bar_refresh_rate=1,accumulate_grad_batches=1\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T13:36:30.760414Z",
     "iopub.status.busy": "2021-11-23T13:36:30.759823Z",
     "iopub.status.idle": "2021-11-23T13:36:30.76797Z",
     "shell.execute_reply": "2021-11-23T13:36:30.766989Z",
     "shell.execute_reply.started": "2021-11-23T13:36:30.760375Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "# # https://stackoverflow.com/questions/36700404/tensorflow-opening-log-data-written-by-summarywriter\n",
    "\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(f\"\\n Fold: {i}==================================================\")\n",
    "#     path = [x for x in os.listdir(f\"./pawnet_lightning_resnet/default/version_{i}/\") if x.startswith(\"events\")][0]\n",
    "#     event_acc = EventAccumulator(os.path.join(f\"pawnet_lightning_resnet/default/version_{i}/\",path), size_guidance={'scalars': 0})\n",
    "#     event_acc.Reload()\n",
    "\n",
    "#     scalars = {}\n",
    "#     for tag in event_acc.Tags()['scalars']:\n",
    "#         events = event_acc.Scalars(tag)\n",
    "#         scalars[tag] = [event.value for event in events]\n",
    "\n",
    "\n",
    "#     print(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T13:36:35.318699Z",
     "iopub.status.busy": "2021-11-23T13:36:35.318158Z",
     "iopub.status.idle": "2021-11-23T13:36:35.323586Z",
     "shell.execute_reply": "2021-11-23T13:36:35.322876Z",
     "shell.execute_reply.started": "2021-11-23T13:36:35.318662Z"
    }
   },
   "outputs": [],
   "source": [
    "# # this allow us to plot all metrics\n",
    "# scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T13:25:09.737112Z",
     "iopub.status.busy": "2021-11-23T13:25:09.736513Z",
     "iopub.status.idle": "2021-11-23T13:25:09.742135Z",
     "shell.execute_reply": "2021-11-23T13:25:09.741375Z",
     "shell.execute_reply.started": "2021-11-23T13:25:09.73707Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "# with open(\"scalars.pkl\",\"wb\") as fout:\n",
    "#     pickle.dump(scalars,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tensorboard (doesnt seem to work on kaggle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "\n",
    "# %tensorboard --logdir ./pawnet_lightning_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
