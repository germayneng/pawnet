{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 04-augmentation\n\nGoal of this notebook is to just explore the dataset, set up some basic utilities ","metadata":{}},{"cell_type":"code","source":"%%bash\n\npip install attrdict\npip install timm","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:33:21.307807Z","iopub.execute_input":"2021-12-08T17:33:21.308823Z","iopub.status.idle":"2021-12-08T17:33:41.148262Z","shell.execute_reply.started":"2021-12-08T17:33:21.308716Z","shell.execute_reply":"2021-12-08T17:33:41.147164Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nimport matplotlib.pyplot as plt\nimport os\nimport tqdm\n\nimport seaborn as sns\nfrom torchvision.io import read_image\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\nfrom attrdict import AttrDict\nimport torch\nimport yaml\nfrom sklearn.model_selection import StratifiedKFold\nimport copy\n# from tqdm import tqdm_notebook\n\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\nfrom timm import create_model\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-12-08T17:34:41.082107Z","iopub.execute_input":"2021-12-08T17:34:41.082791Z","iopub.status.idle":"2021-12-08T17:34:41.091095Z","shell.execute_reply.started":"2021-12-08T17:34:41.082744Z","shell.execute_reply":"2021-12-08T17:34:41.090215Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from pawnet_utility import *","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:34:41.897175Z","iopub.execute_input":"2021-12-08T17:34:41.898124Z","iopub.status.idle":"2021-12-08T17:34:42.696703Z","shell.execute_reply.started":"2021-12-08T17:34:41.898050Z","shell.execute_reply":"2021-12-08T17:34:42.695798Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# check the package version to get reproducible env \n# source: https://www.kaggle.com/rtatman/get-the-versions-of-imported-packages\n\n\"\"\"\nTo be used for kaggle notebook\n\"\"\"\n\nimport pkg_resources\nimport types\ndef get_imports():\n    for name, val in globals().items():\n        if isinstance(val, types.ModuleType):\n            # Split ensures you get root package, \n            # not just imported function\n            name = val.__name__.split(\".\")[0]\n\n        elif isinstance(val, type):\n            name = val.__module__.split(\".\")[0]\n\n        # Some packages are weird and have different\n        # imported names vs. system names\n        if name == \"PIL\":\n            name = \"Pillow\"\n        elif name == \"sklearn\":\n            name = \"scikit-learn\"\n\n        yield name\nimports = list(set(get_imports()))\n\nrequirements = []\nfor m in pkg_resources.working_set:\n    if m.project_name in imports and m.project_name!=\"pip\":\n        requirements.append((m.project_name, m.version))\n\nfor r in requirements:\n    print(\"{}=={}\".format(*r))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T17:43:32.546946Z","iopub.execute_input":"2021-11-30T17:43:32.547903Z","iopub.status.idle":"2021-11-30T17:43:32.560209Z","shell.execute_reply.started":"2021-11-30T17:43:32.547829Z","shell.execute_reply":"2021-11-30T17:43:32.559357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load config\n\nbase_config_manager = BaseConfigLoader(\"../input/d/germmie/config/config.yaml\")\n# model_config = base_config_manager.load_config().","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:34:59.352250Z","iopub.execute_input":"2021-12-08T17:34:59.352665Z","iopub.status.idle":"2021-12-08T17:34:59.373841Z","shell.execute_reply.started":"2021-12-08T17:34:59.352633Z","shell.execute_reply":"2021-12-08T17:34:59.372999Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data\n\nWe will load the data by creating torch datasets as well as dataloader","metadata":{}},{"cell_type":"code","source":"# this is specific to kaggle\n# if running in GCS, replace with our GCP bucket \n# get cache location of the dataset \n# GCS_DS_PATH = KaggleDatasets().get_gcs_path()\nfile_path = base_config_manager.load_config().filepath.kaggle #\"/kaggle/input/petfinder-pawpularity-score/\"\n\n\ntrain_df = pd.read_csv(os.path.join(file_path,\"train.csv\"))\ntest_df = pd.read_csv(os.path.join(file_path,\"test.csv\"))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:35:01.750951Z","iopub.execute_input":"2021-12-08T17:35:01.751252Z","iopub.status.idle":"2021-12-08T17:35:01.798743Z","shell.execute_reply.started":"2021-12-08T17:35:01.751217Z","shell.execute_reply":"2021-12-08T17:35:01.798059Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:35:04.308954Z","iopub.execute_input":"2021-12-08T17:35:04.309502Z","iopub.status.idle":"2021-12-08T17:35:04.334338Z","shell.execute_reply.started":"2021-12-08T17:35:04.309453Z","shell.execute_reply":"2021-12-08T17:35:04.333544Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:35:04.576011Z","iopub.execute_input":"2021-12-08T17:35:04.576310Z","iopub.status.idle":"2021-12-08T17:35:04.590738Z","shell.execute_reply.started":"2021-12-08T17:35:04.576277Z","shell.execute_reply":"2021-12-08T17:35:04.589840Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# create loaders - just for visualization\n# for visualization, we need them to be in the same size\nfile_path = \"/kaggle/input/petfinder-pawpularity-score/\"\ntrain_data = pawnetDataset(annotation_df=train_df,img_dir = os.path.join(file_path,\"train\"),transform = T.Compose([T.Resize([224,224])]))\ntest_data = pawnetDataset(annotation_df=test_df,img_dir = os.path.join(file_path,\"test\"),transform = T.Compose([T.Resize([224,224])]),test=True)\ntrain_loaders = torch.utils.data.DataLoader(train_data,batch_size=30,shuffle=False)\ntest_loaders = torch.utils.data.DataLoader(test_data,batch_size=39,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:35:07.304741Z","iopub.execute_input":"2021-12-08T17:35:07.305049Z","iopub.status.idle":"2021-12-08T17:35:07.313305Z","shell.execute_reply.started":"2021-12-08T17:35:07.305014Z","shell.execute_reply":"2021-12-08T17:35:07.312350Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper to visualize\n# https://towardsdatascience.com/beginners-guide-to-loading-image-data-with-pytorch-289c60b7afec\n\ndef visualize_images(images,nmax):\n    \"\"\"\n    visual images in our loaders\n    \n    Parameters\n    ---------\n    images: image tensor of size (N,H,W,C)\n    nmax: max number of images to plot\n    \"\"\"\n    fig,axes = plt.subplots(figsize=(16,16))\n    axes.set_xticks([])\n    axes.set_yticks([])\n    axes.imshow( make_grid((images.detach()[:nmax]),nrow=6).permute(1,2,0)) # H,W,C\n    plt.savefig(\"train_batch_images.png\")\n    \ndef visualize_batch_images(data_loaders,nmax=64):\n    images, labels = iter(data_loaders).next() # get batch size of image tensor\n    visualize_images(images,nmax=nmax)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:35:10.452441Z","iopub.execute_input":"2021-12-08T17:35:10.453006Z","iopub.status.idle":"2021-12-08T17:35:10.460392Z","shell.execute_reply.started":"2021-12-08T17:35:10.452956Z","shell.execute_reply":"2021-12-08T17:35:10.459683Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"visualize_batch_images(train_loaders)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:45.141092Z","iopub.execute_input":"2021-11-29T16:07:45.141787Z","iopub.status.idle":"2021-11-29T16:07:47.19545Z","shell.execute_reply.started":"2021-11-29T16:07:45.14175Z","shell.execute_reply":"2021-11-29T16:07:47.194364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nAll pre-trained models expect input images normalized in the same way, \ni.e. mini-batches of 3-channel RGB images of shape (3 x H x W), \nwhere H and W are expected to be at least 224. \nThe images have to be loaded in to a range of [0, 1] and then \nnormalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. \nYou can use the following transform to normalize:\n\nhttps://pytorch.org/vision/stable/models.html\n\n\"\"\"\ntrain_transformation = T.Compose(\n            [\n                T.Resize([224,224]),# imgnet needs at least 224\n                T.RandomHorizontalFlip(),\n                T.RandomVerticalFlip(),\n                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n            ]\n        )\n# train_data = pawnetDataset(annotation_df=train_df,img_dir = os.path.join(file_path,\"train\"),transform = train_transformation)\n# # batchsize should be parameter in config\n# train_loader = torch.utils.data.DataLoader(train_data,batch_size=64,num_workers =2, shuffle=True)\n\n\ntest_transformation = T.Compose([\n                T.Resize([224,224]),# imgnet needs at least 224\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n                ]\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.197103Z","iopub.execute_input":"2021-11-29T16:07:47.19734Z","iopub.status.idle":"2021-11-29T16:07:47.204648Z","shell.execute_reply.started":"2021-11-29T16:07:47.19731Z","shell.execute_reply":"2021-11-29T16:07:47.203999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pawnetDataset(annotation_df=train_df,img_dir = os.path.join(file_path,\"train\"),transform = train_transformation)\ntrain_loaders = torch.utils.data.DataLoader(train_data,batch_size=30,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:11:26.403745Z","iopub.execute_input":"2021-11-29T16:11:26.404281Z","iopub.status.idle":"2021-11-29T16:11:26.409748Z","shell.execute_reply.started":"2021-11-29T16:11:26.404246Z","shell.execute_reply":"2021-11-29T16:11:26.408908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_batch_images(train_loaders)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:47.22008Z","iopub.execute_input":"2021-11-29T16:07:47.220944Z","iopub.status.idle":"2021-11-29T16:07:49.007225Z","shell.execute_reply.started":"2021-11-29T16:07:47.220852Z","shell.execute_reply":"2021-11-29T16:07:49.006591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mix up \n","metadata":{}},{"cell_type":"code","source":"train_data = pawnetDataset(annotation_df=train_df,img_dir = os.path.join(file_path,\"train\"),transform = T.Compose([T.Resize([224,224]),T.ConvertImageDtype(torch.float), ]))\n# train_data = pawnetDataset(annotation_df=train_df,img_dir = os.path.join(file_path,\"train\"),transform = train_transformation)\ntrain_loaders = torch.utils.data.DataLoader(train_data,batch_size=30,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:43:28.271724Z","iopub.execute_input":"2021-12-08T17:43:28.272246Z","iopub.status.idle":"2021-12-08T17:43:28.279606Z","shell.execute_reply.started":"2021-12-08T17:43:28.272213Z","shell.execute_reply":"2021-12-08T17:43:28.278190Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"images, labels = iter(train_loaders).next() # get batch size of image tensor","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:43:29.844526Z","iopub.execute_input":"2021-12-08T17:43:29.844814Z","iopub.status.idle":"2021-12-08T17:43:30.130591Z","shell.execute_reply.started":"2021-12-08T17:43:29.844785Z","shell.execute_reply":"2021-12-08T17:43:30.129758Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"labels = labels / 100.","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:43:30.132178Z","iopub.execute_input":"2021-12-08T17:43:30.132468Z","iopub.status.idle":"2021-12-08T17:43:30.138339Z","shell.execute_reply.started":"2021-12-08T17:43:30.132437Z","shell.execute_reply":"2021-12-08T17:43:30.137290Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"indices = torch.randperm(len(images))\n# shuffle images\n# https://discuss.pytorch.org/t/shuffling-a-tensor/25422/9\nnew_images = images[indices].view(images.size())\n# shuffle target\nnew_labels = labels[indices].view(labels.size())","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:43:30.235660Z","iopub.execute_input":"2021-12-08T17:43:30.236553Z","iopub.status.idle":"2021-12-08T17:43:30.264937Z","shell.execute_reply.started":"2021-12-08T17:43:30.236495Z","shell.execute_reply":"2021-12-08T17:43:30.263779Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"alpha = 0.2\nbeta_distribution = torch.distributions.beta.Beta(alpha,alpha)\nt = beta_distribution.sample(sample_shape=torch.Size([len(images)]))\nprint(t)\ntx = t.view(-1,1,1,1)\nty = t.view(-1)\nx = (images * tx) + (new_images * (1-tx))\ny = labels * ty + new_labels * (1-ty)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:43:30.437807Z","iopub.execute_input":"2021-12-08T17:43:30.438344Z","iopub.status.idle":"2021-12-08T17:43:30.538563Z","shell.execute_reply.started":"2021-12-08T17:43:30.438290Z","shell.execute_reply":"2021-12-08T17:43:30.537468Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:43:31.816498Z","iopub.execute_input":"2021-12-08T17:43:31.816981Z","iopub.status.idle":"2021-12-08T17:43:31.824835Z","shell.execute_reply.started":"2021-12-08T17:43:31.816928Z","shell.execute_reply":"2021-12-08T17:43:31.823924Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:43:32.016612Z","iopub.execute_input":"2021-12-08T17:43:32.017031Z","iopub.status.idle":"2021-12-08T17:43:32.024153Z","shell.execute_reply.started":"2021-12-08T17:43:32.016999Z","shell.execute_reply":"2021-12-08T17:43:32.023137Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Cutmix","metadata":{}},{"cell_type":"code","source":"train_data = pawnetDataset(annotation_df=train_df,img_dir = os.path.join(file_path,\"train\"),transform = T.Compose([T.Resize([224,224])]))\ntest_data = pawnetDataset(annotation_df=test_df,img_dir = os.path.join(file_path,\"test\"),transform = T.Compose([T.Resize([224,224])]),test=True)\ntrain_data = CutMix(train_data,num_mix=2,beta=1.0,prob=0.5)\ntrain_loaders = torch.utils.data.DataLoader(train_data,batch_size=30,shuffle=False)\ntest_loaders = torch.utils.data.DataLoader(test_data,batch_size=39,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:38:27.431884Z","iopub.execute_input":"2021-12-08T17:38:27.432639Z","iopub.status.idle":"2021-12-08T17:38:27.440269Z","shell.execute_reply.started":"2021-12-08T17:38:27.432592Z","shell.execute_reply":"2021-12-08T17:38:27.439607Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"images_cm, labels_cm = iter(train_loaders).next() # get batch size of image tensor","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:40:02.634250Z","iopub.execute_input":"2021-12-08T17:40:02.635276Z","iopub.status.idle":"2021-12-08T17:40:03.355757Z","shell.execute_reply.started":"2021-12-08T17:40:02.635237Z","shell.execute_reply":"2021-12-08T17:40:03.354920Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"visualize_batch_images(train_loaders)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:39:21.164017Z","iopub.execute_input":"2021-12-08T17:39:21.164328Z","iopub.status.idle":"2021-12-08T17:39:23.239351Z","shell.execute_reply.started":"2021-12-08T17:39:21.164291Z","shell.execute_reply":"2021-12-08T17:39:23.238146Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Visualize all","metadata":{}},{"cell_type":"code","source":"def visualize_all(images_cm,mixedup_images,images):\n    \"\"\"\n    visual images in our loaders\n    \n    Parameters\n    ---------\n    images: image tensor of size (N,H,W,C)\n    nmax: max number of images to plot\n    \"\"\"\n    fig,axes = plt.subplots(figsize=(16,5),nrows=3)\n    axes[0].set_title(\"Mix up batch of images\")\n    axes[0].set_xticks([])\n    axes[0].set_yticks([])\n    axes[0].imshow( make_grid((mixedup_images.detach()),nrow=7).permute(1,2,0)) # H,W,C\n    \n    axes[1].set_title(\"Cutmix batch of images\")\n    axes[1].set_xticks([])\n    axes[1].set_yticks([])\n    axes[1].imshow( make_grid((images_cm.detach()),nrow=7).permute(1,2,0)) # H,W,C\n    \n    axes[2].set_title(\"Original batch of images\")\n    axes[2].set_xticks([])\n    axes[2].set_yticks([])\n    axes[2].imshow( make_grid((images.detach()),nrow=7).permute(1,2,0)) # H,W,C\n    \n    plt.savefig(\"mixup.png\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:44:33.846167Z","iopub.execute_input":"2021-12-08T17:44:33.846863Z","iopub.status.idle":"2021-12-08T17:44:33.855974Z","shell.execute_reply.started":"2021-12-08T17:44:33.846820Z","shell.execute_reply":"2021-12-08T17:44:33.855143Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# this shows the first 5 images between batch of mixup and batch of OG\n# however since batch size is 30, the mixup is amongst the 30 \nvisualize_all(images_cm[:7],x[:7],images[:7])","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:44:34.090043Z","iopub.execute_input":"2021-12-08T17:44:34.090803Z","iopub.status.idle":"2021-12-08T17:44:34.783398Z","shell.execute_reply.started":"2021-12-08T17:44:34.090763Z","shell.execute_reply":"2021-12-08T17:44:34.782519Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}