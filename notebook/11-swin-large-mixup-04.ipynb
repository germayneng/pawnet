{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training image-based models as baseline\n",
    "\n",
    "\n",
    "General instructions: \n",
    "\n",
    "Fork this notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIt model large + Mixup alpha 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "# %%bash\n",
    "# # for kaggle only \n",
    "# pip install attrdict\n",
    "# pip install timm\n",
    "# pip install pytorch-lightning==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from attrdict import AttrDict\n",
    "import torch\n",
    "import yaml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy\n",
    "import pickle\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# additional lightning \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from timm import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# VM USE THIS\n",
    "##################\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from pawnet.utility import *\n",
    "\n",
    "\n",
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "# you need to import the utility script by uploading to kaggle as pawnet_utility/pawnet_utility.py\n",
    "# from pawnet_utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # check the package version to get reproducible env \n",
    "# # source: https://www.kaggle.com/rtatman/get-the-versions-of-imported-packages\n",
    "\n",
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "\n",
    "# import pkg_resources\n",
    "# import types\n",
    "# def get_imports():\n",
    "#     for name, val in globals().items():\n",
    "#         if isinstance(val, types.ModuleType):\n",
    "#             # Split ensures you get root package, \n",
    "#             # not just imported function\n",
    "#             name = val.__name__.split(\".\")[0]\n",
    "\n",
    "#         elif isinstance(val, type):\n",
    "#             name = val.__module__.split(\".\")[0]\n",
    "\n",
    "#         # Some packages are weird and have different\n",
    "#         # imported names vs. system names\n",
    "#         if name == \"PIL\":\n",
    "#             name = \"Pillow\"\n",
    "#         elif name == \"sklearn\":\n",
    "#             name = \"scikit-learn\"\n",
    "\n",
    "#         yield name\n",
    "# imports = list(set(get_imports()))\n",
    "\n",
    "# requirements = []\n",
    "# for m in pkg_resources.working_set:\n",
    "#     if m.project_name in imports and m.project_name!=\"pip\":\n",
    "#         requirements.append((m.project_name, m.version))\n",
    "\n",
    "# for r in requirements:\n",
    "#     print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "# this object manages all the configurations\n",
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "# config_path = \"../input/config/config.yaml\"\n",
    "\n",
    "##################\n",
    "# VM USE THIS\n",
    "##################\n",
    "config_path = \"../config/config.yaml\"\n",
    "\n",
    "\n",
    "base_config_manager = BaseConfigLoader(config_path)\n",
    "\n",
    "# TODO: edit this for each base image model\n",
    "model_config = base_config_manager.load_config().model.swin_large4_w7_224_m04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'model_name': 'pawnet_lightning_swin_large4_w7_224_mixup04', 'pretrained': 'swin_large_patch4_window7_224', 'n_splits': 5, 'epoch': 20, 'batch_size': 32, 'num_workers': 4, 'dropout': 0.5, 'learning_rate': 1e-05, 'feature_map_out_size': 1536, 'mixup': {'alpha': 0.4}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "We will load the data by creating torch datasets as well as dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# KAGGLE USE THIS\n",
    "##################\n",
    "# this is specific to kaggle\n",
    "# if running in GCS, replace with our GCP bucket\n",
    "# get cache location of the dataset\n",
    "# GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
    "# file_path = base_config_manager.load_config().filepath.kaggle #\"/kaggle/input/petfinder-pawpularity-score/\"\n",
    "\n",
    "\n",
    "##################\n",
    "# VM USE THIS\n",
    "##################\n",
    "file_path = base_config_manager.load_config().filepath.gcs\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(file_path,\"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(file_path,\"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \n",
       "0          0      1        0      0          0     0     0           63  \n",
       "1          0      0        0      0          0     0     0           42  \n",
       "2          0      0        0      1          1     0     0           28  \n",
       "3          0      0        0      0          0     0     0           15  \n",
       "4          0      1        0      0          0     0     0           72  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "2  4e429cead1848a298432a0acad014c9d              0     0     0     1       0   \n",
       "3  80bc3ccafcc51b66303c2c263aa38486              1     0     1     0       0   \n",
       "4  8f49844c382931444e68dffbe20228f4              1     1     1     0       1   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \n",
       "0          1      1        0      0          1     0     1  \n",
       "1          0      1        1      0          0     0     0  \n",
       "2          1      1        1      0          1     1     1  \n",
       "3          0      0        0      0          0     1     0  \n",
       "4          1      0        1      0          1     1     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train basic models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for training - lightning variant \n",
    "\n",
    "* create relevant transformations, validation splits\n",
    "* what this version differs is that we will be using the pytorch lightning framework - this allows easy TPU access for training \n",
    "\n",
    "lightning walkthrough: \n",
    "https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction_guide.html\n",
    "<br>\n",
    "https://devblog.pytorchlightning.ai/train-anything-with-lightning-custom-loops-4be32314c961\n",
    "<br>\n",
    "https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/loop_examples/mnist_lite.py\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All pre-trained models expect input images normalized in the same way, \n",
    "i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), \n",
    "where H and W are expected to be at least 224. \n",
    "The images have to be loaded in to a range of [0, 1] and then \n",
    "normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. \n",
    "You can use the following transform to normalize:\n",
    "\n",
    "https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "\"\"\"\n",
    "train_transformation = T.Compose(\n",
    "            [\n",
    "                T.Resize([224,224]),# imgnet needs at least 224\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.RandomVerticalFlip(),\n",
    "                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n",
    "            ]\n",
    "        )\n",
    "# train_data = pawnetDataset(annotation_df=train_df,img_dir = os.path.join(file_path,\"train\"),transform = train_transformation)\n",
    "# # batchsize should be parameter in config\n",
    "# train_loader = torch.utils.data.DataLoader(train_data,batch_size=64,num_workers =2, shuffle=True)\n",
    "\n",
    "\n",
    "test_transformation = T.Compose([\n",
    "                T.Resize([224,224]),# imgnet needs at least 224\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), # imgnet requirements \n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:12:54.120832Z",
     "iopub.status.busy": "2021-11-22T13:12:54.119896Z",
     "iopub.status.idle": "2021-11-22T13:12:54.127352Z",
     "shell.execute_reply": "2021-11-22T13:12:54.125898Z",
     "shell.execute_reply.started": "2021-11-22T13:12:54.120797Z"
    }
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_everything(1)\n",
    "\n",
    "\n",
    "# perfrom stratified sampling k fold model training\n",
    "skf = StratifiedKFold(n_splits = model_config.n_splits, shuffle = True, random_state = 1)\n",
    "splits = skf.split(train_df[\"Id\"],train_df[\"Pawpularity\"])\n",
    "\n",
    "\n",
    "skf_train_list = [] # to store across folds\n",
    "skf_valid_list = [] # to store across folds\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    print(\"\\n Starting: fold {}\".format(i+1))\n",
    "    \n",
    "    # initialize model \n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    X_train, X_valid = train_df.iloc[train_index], train_df.iloc[test_index]\n",
    "    X_train.reset_index(inplace=True,drop=True)\n",
    "    X_valid.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    # build datamodule\n",
    "    datamodule = PetfinderDataModule(img_dir = os.path.join(file_path,\"train\"),\n",
    "                                     train_df=X_train,\n",
    "                                     val_df=X_valid,\n",
    "                                     train_transformation=train_transformation,\n",
    "                                     test_transformation=test_transformation,\n",
    "                                     batch_size=model_config.batch_size,\n",
    "                                     num_workers=model_config.num_workers)\n",
    "    \n",
    "    \n",
    "    model = pawNetBasic(criterion=criterion,model_config=model_config)\n",
    "    print(model.summarize())\n",
    "    earystopping = EarlyStopping(monitor=\"val_RMSE_loss\",patience=5)\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=\"best_loss\",\n",
    "        monitor=\"val_RMSE_loss\",\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "        save_last=True,\n",
    "    )\n",
    "    logger = TensorBoardLogger(model_config.model_name)\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger, # tensorboard logger\n",
    "        max_epochs=model_config.epoch,\n",
    "        callbacks=[lr_monitor, loss_checkpoint, earystopping],\n",
    "#          callbacks=[lr_monitor, loss_checkpoint],\n",
    "         gpus=1,progress_bar_refresh_rate=1,accumulate_grad_batches=1\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # copy weights to GCS\n",
    "\n",
    "# ! gsutil -m cp -r pawnet_lightning_swin_large4_w7_224_mixup04/* gs://pawnet/11-swin_tiny/pawnet_lightning_swin_large4_w7_224_mixup04/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T13:36:30.760414Z",
     "iopub.status.busy": "2021-11-23T13:36:30.759823Z",
     "iopub.status.idle": "2021-11-23T13:36:30.76797Z",
     "shell.execute_reply": "2021-11-23T13:36:30.766989Z",
     "shell.execute_reply.started": "2021-11-23T13:36:30.760375Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "# # https://stackoverflow.com/questions/36700404/tensorflow-opening-log-data-written-by-summarywriter\n",
    "\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(f\"\\n Fold: {i}==================================================\")\n",
    "#     path = [x for x in os.listdir(f\"./pawnet_lightning_resnet/default/version_{i}/\") if x.startswith(\"events\")][0]\n",
    "#     event_acc = EventAccumulator(os.path.join(f\"pawnet_lightning_resnet/default/version_{i}/\",path), size_guidance={'scalars': 0})\n",
    "#     event_acc.Reload()\n",
    "\n",
    "#     scalars = {}\n",
    "#     for tag in event_acc.Tags()['scalars']:\n",
    "#         events = event_acc.Scalars(tag)\n",
    "#         scalars[tag] = [event.value for event in events]\n",
    "\n",
    "\n",
    "#     print(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T13:36:35.318699Z",
     "iopub.status.busy": "2021-11-23T13:36:35.318158Z",
     "iopub.status.idle": "2021-11-23T13:36:35.323586Z",
     "shell.execute_reply": "2021-11-23T13:36:35.322876Z",
     "shell.execute_reply.started": "2021-11-23T13:36:35.318662Z"
    }
   },
   "outputs": [],
   "source": [
    "# # this allow us to plot all metrics\n",
    "# scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T13:25:09.737112Z",
     "iopub.status.busy": "2021-11-23T13:25:09.736513Z",
     "iopub.status.idle": "2021-11-23T13:25:09.742135Z",
     "shell.execute_reply": "2021-11-23T13:25:09.741375Z",
     "shell.execute_reply.started": "2021-11-23T13:25:09.73707Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "# with open(\"scalars.pkl\",\"wb\") as fout:\n",
    "#     pickle.dump(scalars,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tensorboard (doesnt seem to work on kaggle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "\n",
    "# %tensorboard --logdir ./pawnet_lightning_swin_tiny4_w7_224/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
